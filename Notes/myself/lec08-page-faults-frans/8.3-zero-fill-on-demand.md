# 8.3 Zero Fill On Demand

接下来我将讨论基于page fault和page table可以做的一些其他酷的事情。另一个简单但是使用的非常频繁的功能是zero-fill-on-demand。

当你查看一个用户程序的地址空间时，存在text区域，data区域，同时还有一个BSS区域（注，BSS区域包含了未被初始化或者初始化为0的全局或者静态变量）。当编译器在生成二进制文件时，编译器会填入这三个区域。text区域是程序的指令，data区域存放的是初始化了的全局变量，BSS包含了未被初始化或者初始化为0的全局变量。

之所以这些变量要单独列出来，是因为例如你在C语言中定义了一个大的矩阵作为全局变量，它的元素初始值都是0，为什么要为这个矩阵分配内存呢？其实只需要记住这个矩阵的内容是0就行。

![](<../.gitbook/assets/image (848).png>)

在一个正常的操作系统中，如果执行exec，exec会申请地址空间，里面会存放text和data。因为BSS里面保存了未被初始化的全局变量，这里或许有许多许多个page，但是所有的page内容都为0。

通常可以调优的地方是，我有如此多的内容全是0的page，在物理内存中，我只需要分配一个page，这个page的内容全是0。然后将所有虚拟地址空间的全0的page都map到这一个物理page上。这样至少在程序启动的时候能节省大量的物理内存分配。

![](<../.gitbook/assets/image (787).png>)

当然这里的mapping需要非常的小心，我们不能允许对于这个page执行写操作，因为所有的虚拟地址空间page都期望page的内容是全0，所以这里的PTE都是只读的。之后在某个时间点，应用程序尝试写BSS中的一个page时，比如说需要更改一两个变量的值，我们会得到page fault。那么，对于这个特定场景中的page fault我们该做什么呢？

> 学生回答：我认为我们应该创建一个新的page，将其内容设置为0，并重新执行指令。

是的，完全正确。假设store指令发生在BSS最顶端的page中。我们想要做的是，在物理内存中申请一个新的内存page，将其内容设置为0，因为我们预期这个内存的内容为0。之后我们需要更新这个page的mapping关系，首先PTE要设置成可读可写，然后将其指向新的物理page。这里相当于更新了PTE，之后我们可以重新执行指令。

![](<../.gitbook/assets/image (675).png>)

为什么这是一个好的优化？或者说为什么操作系统要这么做？

> 学生回答：这样节省一部分内存。你可以在需要的时候才申请内存。

是的，这里类似于lazy allocation。假设程序申请了一个大的数组，来保存可能的最大的输入，并且这个数组是全局变量且初始为0。但是最后或许只有一小部分内容会被使用。

第二个好处是在exec中需要做的工作变少了。程序可以启动的更快，这样你可以获得更好的交互体验，因为你只需要分配一个内容全是0的物理page。所有的虚拟page都可以映射到这一个物理page上。

> 学生提问：但是因为每次都会触发一个page fault，update和write会变得更慢吧？
>
> Frans教授：是的，这是个很好的观点，所以这里是实际上我们将一些操作推迟到了page fault再去执行。并且我们期望并不是所有的page都被使用了。如果一个page是4096字节，我们只需要对每4096个字节消耗一次page fault即可。但是这里是个好的观点，我们的确增加了一些由page fault带来的代价。

page fault的代价是多少呢？我们该如何看待它？这是一个与store指令相当的代价，还是说代价要高的多？

> 学生回答：代价要高的多。store指令可能需要消耗一些时间来访问RAM，但是page fault需要走到内核。

是的，在lec06中你们已经看到了，仅仅是在trap处理代码中，就有至少有100个store指令用来存储当前的寄存器。除此之外，还有从用户空间转到内核空间的额外开销。所以，page fault并不是没有代价的，之前问的那个问题是一个非常好的问题。



# **8.3 Zero Fill On Demand**

本节课程介绍了 **zero-fill-on-demand**（按需零填充）的机制，这是在虚拟内存系统中常用的一种优化技术，尤其适用于**BSS（Block Started by Symbol）段**的内存分配。这种技术减少了程序初始启动时的物理内存消耗，同时优化了内存使用效率。

## **1. 用户程序的地址空间与BSS段**

在用户程序的地址空间中，常见的几个主要段如下：

- **text 段**：包含程序指令（代码）。
- **data 段**：保存已初始化的全局变量。
- **BSS 段**：保存未初始化的全局变量，或初始化为 0 的全局变量。

当 **编译器** 生成二进制文件时：

- **text** 和 **data** 段中的数据会被直接写入二进制文件。
- **BSS 段**的数据则不会存入文件，因为它们全部是 0。程序启动时，只需将这些区域初始化为 0 即可。

## **2. Zero-Fill-On-Demand 的核心思想**

**问题**：
如果程序中包含一个非常大的数组（如全局变量数组），其初始值全部为 0，那么为其分配多个物理内存页面会浪费大量资源。大部分页面即使分配了物理内存，也可能从未被实际使用。

**解决方案**：

1. **所有的 BSS 段页面初始状态为只读**，且映射到同一个 **全 0 的物理页面**。
2. 当程序试图修改这些页面时，会触发 **page fault**。
3. **Page Fault Handler** 会为该页面分配一个新的物理页面，将其初始化为 0，并更新 **PTE（Page Table Entry）** 中的权限为可读可写。
4. 更新 PTE 后，重新执行触发 page fault 的指令。

## **3. Zero-Fill-On-Demand 的流程**

1. **程序启动时**：
   - 内核只需分配一个全 0 的物理页面，并将多个虚拟页面映射到这个物理页面上。
   - 这些虚拟页面的 **PTE** 均设置为 **只读**，以避免不必要的修改。
2. **当应用程序试图写入 BSS 段时**：
   - 由于页面是只读的，尝试写操作会触发 **page fault**。
3. **Page Fault Handler 的处理**：
   - 在 page fault handler 中：
     1. **分配一个新的物理页面**，并将其内容初始化为 0。
     2. **更新 PTE**，使该虚拟页面指向新的物理页面，并设置为可读可写。
     3. 重新执行导致 page fault 的指令。

## 4. Zero-Fill-On-Demand 的优势

1. **节省物理内存**：
   - 只在需要时分配物理页面，避免为未使用的数据浪费内存资源。
2. **加快程序启动速度**：
   - 程序启动时，内核无需预先分配所有需要的物理内存页面，只需映射一个全 0 的页面即可。

## **5. Zero-Fill-On-Demand 的缺点与性能权衡**

### **潜在缺点**：

1. **增加了 Page Fault 的频率**：
   - 每次写入 BSS 段的新页面都会触发一次 page fault，增加了系统的开销。
2. **性能损耗**：
   - 处理 **page fault** 需要从用户空间切换到内核空间，并且涉及复杂的 trap 处理逻辑，导致系统开销大。

### **page fault 的代价**：

- **Store 指令** 只需消耗时间访问 RAM。

- Page Fault

   需要：

  1. 切换到内核空间。
  2. 保存和恢复所有寄存器（这可能涉及上百条指令）。
  3. 更新 page table 和 PTE。

## **6. 实际应用中的优化**

在实际的操作系统中，例如 **Linux**，BSS 段和其他未初始化的内存区域通常会利用类似的 **zero-fill-on-demand** 技术。这样可以在程序启动时节省内存，并优化系统的整体性能。

## **7. 问答环节**

**Q1**：为什么 Zero-Fill-On-Demand 是一种好的优化？
**A**：它减少了内存浪费，并且使得程序启动更快。程序只在需要时才分配页面，而不是一次性分配全部页面。

**Q2**：增加 page fault 会影响性能吗？
**A**：是的。虽然减少了内存浪费，但频繁的 page fault 会增加系统开销，因为每次 page fault 都需要从用户空间切换到内核空间。

**Q3**：如何权衡性能与内存节省？
**A**：这取决于应用的需求和使用场景。如果大多数页面会被使用，则 eager allocation 性能更好；如果大部分页面不会使用，则 lazy allocation 和 zero-fill-on-demand 是更好的选择。

## **8. 总结**

**Zero-Fill-On-Demand** 是一种高效的内存管理技术，它通过在需要时分配页面来减少内存浪费，并提高程序启动速度。然而，这种优化也会增加 page fault 的频率，导致一定的性能开销。系统设计人员需要在性能与内存节省之间找到合适的平衡点。在后续实验中，你将有机会实现和测试类似的技术，深入理解它们在操作系统中的实际应用。
