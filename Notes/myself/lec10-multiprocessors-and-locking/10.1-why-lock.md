# 10.1 为什么要使用锁？

（00:00 - 01:33）是上一个lab的抽查问答，与内容无关故跳过。

今天的课程的内容是锁。这节课偏向于理论介绍，并且或许会与其他课程中有关锁的内容有些重合，不过这节课更关注在内核和操作系统中使用的锁。

首先，我们来看一下为什么我们需要锁？故事要从应用程序想要使用多个CPU核开始。使用多个CPU核可以带来性能的提升，如果一个应用程序运行在多个CPU核上，并且执行了系统调用，那么内核需要能够处理并行的系统调用。如果系统调用并行的运行在多个CPU核上，那么它们可能会并行的访问内核中共享的数据结构。到目前为止，你们也看到了XV6有很多共享的数据结构，例如proc、ticks和我们之后会看到的buffer cache等等。当并行的访问数据结构时，例如一个核在读取数据，另一个核在写入数据，我们需要使用锁来协调对于共享数据的更新，以确保数据的一致性。所以，我们需要锁来控制并确保共享的数据是正确的。

但是实际的情况有些令人失望，因为我们想要通过并行来获得高性能，我们想要并行的在不同的CPU核上执行系统调用，但是如果这些系统调用使用了共享的数据，我们又需要使用锁，而锁又会使得这些系统调用串行执行，所以最后锁反过来又限制了性能。

![](<../.gitbook/assets/image (463) (1) (1) (1) (1).png>)

所以现在我们处于一个矛盾的处境，出于正确性，我们需要使用锁，但是考虑到性能，锁又是极不好的。这就是现实，我们接下来会看看如何改善这个处境。

以上是一个大概的介绍，但是回到最开始，为什么应用程序一定要使用多个CPU核来提升性能呢？这个实际上与过去几十年技术的发展有关，下面这张非常经典的图可以解释为什么。

![](<../.gitbook/assets/image (840).png>)

这张图有点复杂，X轴是时间，Y轴是单位，Y轴具体意义取决于特定的曲线。这张图中的核心点是，大概从2000年开始：

* CPU的时钟频率就没有再增加过了（绿线）。
* 这样的结果是，CPU的单线程性能达到了一个极限并且也没有再增加过（蓝线）。
* 但是另一方面，CPU中的晶体管数量在持续的增加 （深红色线）。
* 所以现在不能通过使用单核来让代码运行的更快，要想运行的更快，唯一的选择就是使用多个CPU核。所以从2000年开始，处理器上核的数量开始在增加（黑线）。

所以现在如果一个应用程序想要提升性能，它不能只依赖单核，必须要依赖于多核。这也意味着，如果应用程序与内核交互的较为紧密，那么操作系统也需要高效的在多个CPU核上运行。这就是我们对内核并行的运行在多个CPU核上感兴趣的直接原因。你们可能之前已经看过上面这张图，但我们这里回顾一下背景知识也是极好的。

那为什么要使用锁呢？前面我们已经提到了，是为了确保正确性。当一份共享数据同时被读写时，如果没有锁的话，可能会出现race condition，进而导致程序出错。race condition是比较讨厌的，我们先来看看什么是race condition。我们接下来会在XV6中创建一个race condition，然后看看它的表象是什么。

kalloc.c文件中的kfree函数会将释放的page保存于freelist中。

![](<../.gitbook/assets/image (655).png>)

freelist是XV6中的一个非常简单的数据结构，它会将所有的可用的内存page保存于一个列表中。这样当kalloc函数需要一个内存page时，它可以从freelist中获取。从函数中可以看出，这里有一个锁kmem.lock，在加锁的区间内，代码更新了freelist。现在我们将锁的acquire和release注释上，这样原来在上锁区间内的代码就不再受锁保护，并且不再是原子执行的。

![](<../.gitbook/assets/image (812).png>)

之后运行make qemu重新编译XV6，

![](<../.gitbook/assets/image (832).png>)

我们可以看到XV6已经运行起来，并且我们应该已经运行了一些对于kfree的调用，看起来一切运行都正常啊。

接下来运行一下usertest，究竟能不能成功呢？有人想猜一下吗？

> 学生回答：如果发生了race condition就会丢失一些内存page，如果没有发生就能成功。

是的，race condition不一定会发生，让我们来运行一下usertest，看看究竟会发生什么。我这里通过qemu模拟了3个CPU核，这3个核是并行运行的。但是如刚刚那位同学指出的，race condition不一定会发生，因为当每一个核在每一次调用kfree函数时，对于freelist的更新都还是原子操作，这与有锁是一样，这个时候没有问题。有问题的是，当两个处理器上的两个线程同时调用kfree，并且交错执行更新freelist的代码。

我们来看一下usertest运行的结果，可以看到已经有panic了。所以的确有一些race condition触发了panic。但是如前面的同学提到的，还有一些其他的race condition会导致丢失内存page，这种情况下，usertest运行并不会有问题。

![](<../.gitbook/assets/image (732).png>)

所以race condition可以有不同的表现形式，并且它可能发生，也可能不发生。但是在这里的usertests中，很明显发生了什么。

------







# 10.1 为什么要使用锁？

本节课引入了锁的概念，并探讨了锁在并行环境下的重要性以及引入的性能权衡。课程还展示了在不使用锁时的race condition（竞争条件）及其影响。

## 1. 多核并行与锁的需求

在现代应用程序中，多个CPU核并行执行带来了性能提升，尤其当应用程序运行在多核环境并进行系统调用时，内核必须能够处理并行的系统调用。多个核并行访问内核中的共享数据结构（如`proc`、`ticks`、`buffer cache`等）时，需要锁来确保数据的一致性。例如：

- **共享数据的一致性**：==当一个CPU核读取数据而另一个核写入数据时，锁可以确保读写的顺序一致，不会导致数据错误。==
- **锁的两难**：==尽管锁保证了数据正确性，但它会使得系统调用在多核环境下串行执行，限制了并行性，从而降低了性能。这一矛盾是并行程序设计中的核心挑战。==

## 2. 为什么必须依赖多核来提升性能？

上世纪90年代至2000年初，CPU的单线程性能增长迅速。然而在2000年左右，技术发展出现了重要转变：

- **时钟频率的增长停滞**：CPU的时钟频率在2000年后基本不再增加（绿线）。
- **单线程性能的极限**：CPU单线程性能达到了极限（蓝线）。
- **晶体管数量持续增加**：==CPU中的晶体管数量不断增加（深红线），从而实现了更多CPU核（黑线）。==

在这一背景下，应用程序必须依赖多个CPU核来提高性能，这也要求内核在多核环境中高效运行。

## 3. 锁的核心作用：避免Race Condition

为了确保共享数据在并行访问下的正确性，必须使用锁，否则会发生race condition：

- **什么是Race Condition**：当多个CPU核并行访问和修改共享数据结构时，若没有锁保护，就可能出现race condition，导致数据不一致或程序错误。
- **在XV6中展示Race Condition**：==课程使用`kalloc.c`中的`kfree`函数作为示例，展示了在没有锁保护的情况下如何触发race condition。`kfree`将释放的page加入`freelist`，一个简单的链表数据结构，用于保存可用的内存page。若注释掉对`kmem.lock`的acquire和release操作，使得代码无锁运行，则`freelist`更新操作不再是原子的。==

## 4. XV6中的Race Condition实验

将XV6重新编译并运行`make qemu`后，系统表面上似乎正常运行。但当运行`usertest`时，会出现不确定的行为，取决于是否触发了race condition：

- **Race Condition的触发**：==若两个CPU核并发执行`kfree`并在更新`freelist`时交错执行，则会触发race condition。该条件下会出现数据丢失或内存page错误。==
- **usertest的表现**：若race condition发生，系统可能出现panic，导致测试失败。若race condition未触发，usertest可以正常运行。即使运行成功，也可能存在内存page丢失的问题，但此问题不会显现于测试结果中。

### 总结

通过本次实验演示，我们看到了race condition的复杂性与不可预知性。锁的引入确保了共享数据在并行环境下的正确性，尽管会带来性能损失，这也是并行编程中必须权衡的问题。





## 拓展

### 问题：详细解释一下Race Condition

**Race Condition（竞争条件）** 是指在多线程或多进程环境下，多个线程或进程**同时访问和修改共享资源**时，由于执行顺序的不确定性而产生的**非预期结果**或**错误**。竞争条件通常出现在并发程序中，当两个或多个线程或进程对同一个数据进行读写且不加锁保护时，就可能出现这种情况。

#### 竞争条件的成因

在并发执行的过程中，如果多个线程（或进程）对共享数据执行一系列操作，以下条件会导致竞争条件：

1. **共享资源**：多个线程或进程在操作同一个变量、文件、数据库或数据结构等资源。
2. **非原子操作**：对共享资源的操作（如读取、写入）并不是一个单一的、不可分割的步骤，而是由多个步骤组成的。
3. **不确定的执行顺序**：由于线程调度的不确定性，操作的顺序可能不同，导致结果也不一致。

#### 竞争条件的典型示例

一个简单的竞争条件例子是银行账户的余额更新。假设两个线程要执行对账户余额的增减操作：

```
// 共享变量
int balance = 100;

// 线程1：存款100
balance = balance + 100;

// 线程2：取款50
balance = balance - 50;
```

#### 竞争条件的具体表现

假设线程 1 和线程 2 都试图同时操作 `balance` 变量，并且 `balance = balance + 100` 和 `balance = balance - 50` 这些操作并非原子操作（即不是一步完成的），它们可能会被拆分为几个步骤，例如：

1. 读取 `balance` 的当前值。
2. 计算新的值。
3. 将新值写回 `balance`。

由于这三个步骤不是原子操作，如果两个线程交替执行这些步骤，可能会产生意料之外的结果。例如：

- 初始状态：`balance = 100`
- **线程1** 读取 `balance`（100）并计算存款后的值（200）。
- **线程2** 读取 `balance`（100）并计算取款后的值（50）。
- **线程1** 将计算结果（200）写入 `balance`。
- **线程2** 将计算结果（50）写入 `balance`。

最终结果为 `balance = 50`，与预期的 `150` 不符，这就是典型的竞争条件。

#### 竞争条件的危害

- **数据不一致**：导致共享数据出现不一致或错误值，可能会影响系统稳定性。
- **系统崩溃**：对于关键资源的竞争，可能会导致系统出现死锁或崩溃。
- **安全问题**：在安全相关系统中，竞争条件可能导致意图被绕过，带来安全隐患。

#### 解决竞争条件的方法

##### 1. **互斥锁（Mutex）**

- 使用互斥锁对共享资源进行保护，确保每次只有一个线程能够访问资源。
- 互斥锁是一种常用的同步机制，能够将代码的某个关键部分（即临界区）锁定，从而避免多个线程同时执行。

```C
pthread_mutex_t lock;
pthread_mutex_init(&lock, NULL);

pthread_mutex_lock(&lock);
// critical section
balance = balance + 100;
pthread_mutex_unlock(&lock);
```

##### 2. **信号量（Semaphore）**

- 信号量是一种通用的同步机制，可以控制对资源的访问数量。例如，限制同一时刻最多允许 N 个线程访问共享资源。
- 信号量通常适用于资源数量有限、需要共享的场景。

##### 3. **原子操作**

- 使用原子操作可以确保在多线程环境下，某些简单的操作（如加法、减法）在执行过程中不会被中断。
- 许多现代编程语言和硬件支持原子操作，例如 C 语言的 `__sync_fetch_and_add()`。

##### 4. **读写锁（Reader-Writer Lock）**

- 读写锁适用于读多写少的情况，允许多个线程并发读取资源，但在写入时则会阻止其他线程的访问。

##### 5. **屏障（Barrier）**

- 屏障用于在并发操作中同步线程执行的进度，确保所有线程在特定点之前完成当前工作。所有线程到达屏障后，才能继续往下执行，确保数据在这一点前保持一致。

#### 总结

竞争条件发生在多个线程同时对共享资源进行非原子操作时，容易导致数据错误或系统不稳定。可以通过加锁、原子操作、读写锁等同步机制来避免竞争条件，确保线程安全。
