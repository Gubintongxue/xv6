# 10.3 什么时候使用锁？

很明显，锁限制了并发性，也限制了性能。那这带来了一个问题，什么时候才必须要加锁呢？我这里会给你们一个非常保守同时也是非常简单的规则：如果两个进程访问了一个共享的数据结构，并且其中一个进程会更新共享的数据结构，那么就需要对于这个共享的数据结构加锁。

![](<../.gitbook/assets/image (652).png>)

这是个保守的规则，如果一个数据结构可以被多个进程访问，其中一个进程会更新这个数据，那么可能会产生race condition，应该使用锁来确保race condition不会发生。

但是同时，这条规则某种程度上来说又太过严格了。如果有两个进程共享一个数据结构，并且其中一个进程会更新这个数据结构，在某些场合不加锁也可以正常工作。不加锁的程序通常称为lock-free program，不加锁的目的是为了获得更好的性能和并发度，不过lock-free program比带锁的程序更加复杂一些。这节课的大部分时间我们还是会考虑如何使用锁来控制共享的数据，因为这已经足够复杂了，很多时候就算直接使用锁也不是那么的直观。

矛盾的是，有时候这个规则太过严格，而有时候这个规则又太过宽松了。除了共享的数据，在一些其他场合也需要锁，例如对于printf，如果我们将一个字符串传递给它，XV6会尝试原子性的将整个字符串输出，而不是与其他进程的printf交织输出。尽管这里没有共享的数据结构，但在这里锁仍然很有用处，因为我们想要printf的输出也是序列化的。

所以，这条规则并不完美，但是它已经是一个足够好的指导准则。

> 学生提问：有没有可能两个进程同时acquire锁，然后同时修改数据？
>
> Franz教授：不会的，对于锁来说不可能同时被两个进程acquire，我们之后会看到acquire是如何实现的，现在从acquire的说明来看，任何时间最多只能有一个进程持有锁。

因为有了race condition，所以需要锁。我们之前在kfree函数中构造的race condition是很容易被识别到的，实际上如果你使用race detection工具，就可以立即找到它。但是对于一些更复杂的场景，就不是那么容易探测到race condition。

那么我们能通过自动的创建锁来自动避免race condition吗？如果按照刚刚的简单规则，一旦我们有了一个共享的数据结构，任何操作这个共享数据结构都需要获取锁，那么对于XV6来说，每个结构体都需要自带一个锁，当我们对于结构体做任何操作的时候，会自动获取锁。

可是如果我们这样做的话，结果就太过严格了，所以不能自动加锁。接下来看一个具体的例子。

![](<../.gitbook/assets/image (700).png>)

假设我们有一个对于rename的调用，这个调用会将文件从一个目录移到另一个目录，我们现在将文件d1/x移到文件d2/y。

如果我们按照前面说的，对数据结构自动加锁。现在我们有两个目录对象，一个是d1，另一个是d2，那么我们会先对d1加锁，删除x，之后再释放对于d1的锁；之后我们会对d2加锁，增加y，之后再释放d2的锁。这是我们在使用自动加锁之后的一个假设的场景。

![](<../.gitbook/assets/image (774).png>)

在这个例子中，我们会有错误的结果，那么为什么这是一个有问题的场景呢？为什么这个场景不能正常工作？

在我们完成了第一步，也就是删除了d1下的x文件，但是还没有执行第二步，也就是创建d2下的y文件时。其他的进程会看到什么样的结果？是的，其他的进程会看到文件完全不存在。这明显是个错误的结果，因为文件还存在只是被重命名了，文件在任何一个时间点都是应该存在的。但是如果我们按照上面的方式实现锁的话，那么在某个时间点，文件看起来就是不存在的。

所以这里正确的解决方法是，我们在重命名的一开始就对d1和d2加锁，之后删除x再添加y，最后再释放对于d1和d2的锁。&#x20;

![](<../.gitbook/assets/image (837).png>)

在这个例子中，我们的操作需要涉及到多个锁，但是直接为每个对象自动分配一个锁会带来错误的结果。在这个例子中，锁应该与操作而不是数据关联，所以自动加锁在某些场景下会出问题。

> 学生提问：可不可以在访问某个数据结构的时候，就获取所有相关联的数据结构的锁？
>
> Frans教授：这是一种实现方式。但是这种方式最后会很快演进成big kernel lock，这样你就失去了并发执行的能力，但是你肯定想做得更好。这里就是使用锁的矛盾点了，如果你想要程序简单点，可以通过coarse-grain locking（注，也就是大锁），但是这时你就失去了性能。



------



# 10.3 什么时候使用锁？

本节课探讨了在多核并发环境下如何决定是否使用锁以及何时使用锁的原则。锁的引入可以避免数据冲突（race condition），但同时也会限制并发性和性能，因此需要合理地使用锁。

## 1. 什么时候必须使用锁？

一个简单而保守的加锁规则是：

- **若两个进程访问同一个共享数据结构，且其中一个会更新该数据结构，则需要对该数据结构加锁**。
  这一原则可以避免race condition，因为若没有锁保护，当进程同时访问和更新共享数据时，可能会导致数据不一致的问题。

### 例外情况：Lock-free编程

在某些高性能应用中，为提高并发性，==可能会采用无锁（lock-free）编程。无锁程序不使用锁来协调并发访问，而是通过特殊的编程技术来保证数据的安全性。然而，无锁程序的设计和实现较为复杂，难以确保正确性。因此本课程仍主要集中在如何合理使用锁来控制共享数据。==

## 2. 加锁原则的适用范围

在某些场景中，加锁原则过于严格，可能带来不必要的开销。而在另一些场景中，该规则可能又过于宽松。例如：

- **不涉及数据的操作也可使用锁**：例如`printf`函数在输出时使用锁，以避免不同进程的输出内容交织在一起，确保输出的序列化。==这说明锁不仅用于保护共享数据结构，还可用于保障操作的顺序性。==

## 3. 自动加锁的挑战

尽管锁可以有效地避免race condition，但==自动为每个数据结构加锁并不总是合适==：

- **自动加锁的限制**：==如果为每个共享数据结构自动加锁，会带来过度同步，导致不必要的性能损失。==
- **示例：文件重命名操作中的锁管理**
  ==假设需要将文件从目录`d1`移动到目录`d2`。若自动加锁，每个目录对象都会被单独加锁：先对`d1`加锁并删除`d1`中的文件`x`，然后释放`d1`的锁；接着对`d2`加锁并在其中添加文件`y`。这种方式会导致问题，因为在第一步和第二步之间的时间点，系统会短暂显示文件完全不存在。==

### 正确的加锁方法：关联操作的锁

在涉及多步骤操作的场景下，正确的方式是将相关对象的锁一起获取。例如：

1. **一次性加锁**：==在重命名开始时同时加锁`d1`和`d2`，确保在完成整个重命名操作之前不释放这两个锁。==
2. **顺序解锁**：只有在操作完全完成（即从`d1`中删除`x`并在`d2`中添加`y`后）才释放锁。这种方式保证了操作的原子性，避免了文件短暂丢失的错误。

## 4. 锁的粒度与性能平衡

> **学生提问**：能否在访问数据结构时一次性获取所有关联数据的锁？
>
> **Frans教授**：==这是可行的，但容易演变成big kernel lock，导致并发性下降。锁的粒度和性能是一个权衡问题，使用粗粒度锁可以简化程序，但可能牺牲并发性能。==

------

总结来看，锁的使用需要平衡数据一致性和系统性能。简单而保守的加锁规则在大多数场景下足够使用，但在复杂操作中应注意加锁的策略，使锁与操作关联，以确保系统的正确性和效率
