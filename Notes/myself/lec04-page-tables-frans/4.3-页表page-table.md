# 4.3 页表（Page Table）

我们如何能够实现地址空间呢？或者说如何在一个物理内存上，创建不同的地址空间？

最常见的方法，同时也是非常灵活的一种方法就是使用页表（Page Tables）。==页表是在硬件中通过处理器和内存管理单元（Memory Management Unit）实现。==所以，在你们的脑海中，应该有这么一张图：CPU正在执行指令，例如_sd $7, (a0)。_

![](<../.gitbook/assets/image (301).png>)

### 虚拟地址 -> mmu

==对于任何一条带有地址的指令，其中的地址应该认为是虚拟内存地址而不是物理地址。==假设寄存器a0中是地址0x1000，那么这是一个虚拟内存地址。==虚拟内存地址会被转到内存管理单元（MMU，Memory Management Unit）==

![](<../.gitbook/assets/image (241).png>)

### mmu-> 物理地址 ->索引物理内存

==内存管理单元会将虚拟地址翻译成物理地址。之后这个物理地址会被用来索引物理内存，并从物理内存加载，或者向物理内存存储数据。==

![](<../.gitbook/assets/image (398).png>)

==从CPU的角度来说，一旦MMU打开了，它执行的每条指令中的地址都是虚拟内存地址。==

为了能够完成虚拟内存地址到物理内存地址的翻译，MMU会有一个表单，表单中，一边是虚拟内存地址，另一边是物理内存地址。举个例子，虚拟内存地址0x1000对应了一个我随口说的物理内存地址0xFFF0。这样的表单可以非常灵活。

![](<../.gitbook/assets/image (274).png>)

### 页表存放在内存/物理内存，CPU寄存器保存其位置，mmu找

通常来说，==内存地址对应关系的表单也保存在内存中。所以CPU中需要有一些寄存器用来存放表单在物理内存中的地址。==现在，在内存的某个位置保存了地址关系表单，**我们假设这个位置的物理内存地址是0x10。那么在RISC-V上一个叫做SATP的寄存器会保存地址0x10。**

![](<../.gitbook/assets/image (355).png>)

这样，==CPU就可以告诉MMU，可以从哪找到将虚拟内存地址翻译成物理内存地址的表单。==

### 学生提问：

> 学生提问：所以MMU并不会保存page table，它只会从内存中读取page table，然后完成翻译，是吗？
>
> Frans教授：是的，这就是你们应该记住的。page table保存在内存中，MMU只是会去查看page table，我们接下来会看到，page table比我们这里画的要稍微复杂一些。

### 每个应用程序都有独立的表单，CPU切换应用程序会切换SATP寄存器内容

这里的基本想法是每个应用程序都有自己独立的表单，并且这个表单定义了应用程序的地址空间。==所以当操作系统将CPU从一个应用程序切换到另一个应用程序时，**同时也需要切换SATP寄存器中的内容，从而指向新的进程保存在物理内存中的地址对应表单。**==

这样的话，cat程序和Shell程序中相同的虚拟内存地址，就可以翻译到不同的物理内存地址，因为每个应用程序都有属于自己的不同的地址对应表单。这样说得通吗？

### 学生提问

> 学生提问：刚刚说到SATP寄存器会根据进程而修改，我猜每个进程对应的SATP值是由内核保存的？
>
> Frans教授：是的。内核会写SATP寄存器，写SATP寄存器是一条特殊权限指令。所以，用户应用程序不能通过更新这个寄存器来更换一个地址对应表单，否则的话就会破坏隔离性。**所以，只有运行在kernel mode的代码可以更新这个寄存器。**



前面都是最基本的介绍，我们在前面画的图还有做的解释都比较初级且存在明显不合理的地方。有一件事情我刚刚没有提到，这里的表单是如何工作的？从刚刚画的图看来，对于每个虚拟地址，在表单中都有一个条目，如果我们真的这么做，表单会有多大？原则上说，在RISC-V上会有多少地址，==或者一个寄存器可以保存多少个地址？寄存器是64bit的，所以有多少个地址呢？是的，2^64个地址，所以如果我们以地址为粒度来管理，表单会变得非常巨大。实际上，**所有的内存都会被这里的表单耗尽**，==所以这一点也不合理。

所以，实际情况不可能是一个虚拟内存地址对应page table中的一个条目。

### 为每个page（4KB）创建一个表单条目

接下来我将分两步介绍RISC-V中是如何工作的。

==第一步：不要为每个地址创建一条表单条目，而是为每个page创建一条表单条目，所以每一次地址翻译都是针对一个page。==

==而RISC-V中，一个page是4KB，也就是4096Bytes。==这个大小非常常见，几乎所有的处理器都使用4KB大小的page或者支持4KB大小的page。

### 内存地址划分 虚拟内存地址->index和offset

现在，内存地址的翻译方式略微的不同了。首先对于虚拟内存地址，我们将它划分为两个部分，index和offset，==index用来查找page，offset对应的是一个page中的哪个字节。==

![](<../.gitbook/assets/image (183).png>)

### mmu->index+offset->物理地址

==当MMU在做地址翻译的时候，通过读取虚拟内存地址中的index可以知道物理内存中的page号，==这个page号对应了物理内存中的4096个字节。之后虚拟内存地址中的offset指向了page中的4096个字节中的某一个，假设offset是12，那么page中的第12个字节被使用了。==将offset加上page的起始地址，就可以得到物理内存地址。==

![](<../.gitbook/assets/image (224).png>)

### 虚拟地址大小

有关RISC-V的一件有意思的事情是，虚拟内存地址都是64bit，这也说的通，因为RISC-V的寄存器是64bit的。但是实际上，==在我们使用的RSIC-V处理器上，并不是所有的64bit都被使用了，也就是说高25bit并没有被使用。这样的结果是限制了虚拟内存地址的数量，虚拟内存地址的数量现在只有2^39个，大概是512GB。==当然，如果必要的话，最新的处理器或许可以支持更大的地址空间，只需要将未使用的25bit拿出来做为虚拟内存地址的一部分即可。

在剩下的39bit中，有27bit被用来当做index，12bit被用来当做offset。==offset必须是12bit，因为对应了一个page的4096个字节。==

![](<../.gitbook/assets/image (204).png>)

### 物理地址大小

在RISC-V中，物理内存地址是56bit。所以物理内存可以大于单个虚拟内存地址空间，但是也最多到2^56。大多数主板还不支持2^56这么大的物理内存，但是原则上，如果你能造出这样的主板，那么最多可以支持2^56字节的物理内存。

==物理内存地址是56bit，其中44bit是物理page号（PPN，Physical Page Number），剩下12bit是offset完全继承自虚拟内存地址（也就是地址转换时，**只需要将虚拟内存中的27bit翻译成物理内存中的44bit的page号，剩下的12bitoffset直接拷贝过来即可**）。==

![](<../.gitbook/assets/image (225).png>)

### 补充：**MMU 与页表的关系**

1. **MMU（Memory Management Unit）**：
   - MMU 是一个硬件单元，负责在 **CPU 访问虚拟地址时，将其转换为物理地址**。
   - MMU 会根据 **页表（Page Table）** 记录的信息，完成虚拟页号（VPN）到物理页号（PPN）的映射。
   - **页表** 是一个数据结构，由操作系统维护，记录了虚拟页与物理页之间的映射关系。MMU 使用这些页表来完成地址转换。
2. **页表的工作原理**：
   - 页表将虚拟地址的高位部分（虚拟页号，VPN）与物理内存中的物理页号（PPN）进行映射。
   - 虚拟地址中的低位部分（页内偏移，Offset）不会被转换，直接**复制到物理地址的低位**。

#### **描述的转换过程**

1. **虚拟地址结构**：
   - 虚拟地址（假设是 39 位）：
     - 高 27 位：**虚拟页号（VPN）**，需要页表转换成物理页号。
     - 低 12 位：**页内偏移（Offset）**，无需转换。
2. **物理地址结构**：
   - 物理地址（56 位）：
     - 高 44 位：**物理页号（PPN）**。MMU 将 VPN 翻译为 PPN。
     - 低 12 位：**页内偏移**。直接从虚拟地址拷贝，不需要转换。
3. **地址转换流程**：
   - **CPU 提供虚拟地址**，MMU 检查页表，找到虚拟页号（27 位 VPN）对应的物理页号（44 位 PPN）。
   - **页内偏移（12 位 Offset）** 被直接复制到物理地址的低 12 位部分。
   - 最终得到**完整的物理地址（44 位 PPN + 12 位 Offset）**。

#### **总结：页表和 MMU 的合作关系**

- **MMU** 是执行地址转换的硬件，**页表** 是存储映射关系的数据结构。
- 在描述的过程中，**MMU 使用页表来完成虚拟页号到物理页号的映射**，同时直接复制页内偏移（Offset）。因此，这个过程涉及的是 MMU 通过查询页表完成地址转换的过程。

------





这里有什么问题吗？这些的内容还挺重要的，你们需要掌握这的内容才能做出下一个page table lab。

### 学生提问

> 学生提问：我想知道4096字节作为一个page，这在物理内存中是连续的吗？
>
> Frans教授：**是的，在物理内存中，这是连续的4096个字节。所以物理内存是以4096为粒度使用的。**
>
> 同一个学生：**所以offset才是12bit，这样就足够覆盖4096个字节？**
>
> Frans教授：**是的，page中的每个字节都可以被offset索引到。**
>
> 同一个学生：图中的56bit又是根据什么确定的？
>
> Frans教授：这是由硬件设计人员决定的。所以RISC-V的设计人员认为56bit的物理内存地址是个不错的选择。可以假定，他们是通过技术发展的趋势得到这里的数字。比如说，设计是为了满足5年的需求，可以预测物理内存在5年内不可能超过2^56这么大。或许，他们预测是的一个小得多的数字，但是为了防止预测错误，他们选择了像2^56这么大的数字。这里说的通吗？很多同学都问了这个问题。
>
> 学生提问：如果虚拟内存最多是2^27（注，最多应该是2^39），而物理内存最多是2^56，这样我们可以有多个进程都用光了他们的虚拟内存，但是物理内存还有剩余，对吗？
>
> Frans教授：是的，完全正确。
>
> 学生提问：因为这是一个64bit的机器，为什么硬件设计人员本可以用64bit但是却用了56bit？
>
> Frans教授：选择56bit而不是64bit是因为在主板上只需要56根线。
>
> 学生提问：我们从CPU到MMU之后到了内存，但是不同的进程之间的怎么区别？比如说Shell进程在地址0x1000存了一些数据，ls进程也在地址0x1000也存了一些数据，我们需要怎么将它们翻译成不同的物理内存地址。
>
> Frans教授：SATP寄存器包含了需要使用的地址转换表的内存地址。所以ls有自己的地址转换表，cat也有自己的地址转换表。每个进程都有完全属于自己的地址转换表。

通过前面的第一步，我们现在使得地址转换表是以page为粒度，而不是以单个内存地址为粒度，现在这个地址转换表已经可以被称为page table了。但是目前的设计还不能满足实际的需求。

如果每个进程都有自己的page table，那么每个page table表会有多大呢？

![](<../.gitbook/assets/image (344).png>)

这个page table最多会有2^27个条目（虚拟内存地址中的index长度为27），这是个非常大的数字。==如果每个进程都使用这么大的page table，进程需要为page table消耗大量的内存，并且很快物理内存就会耗尽。==

### 多级页表

所以实际上，硬件并不是按照这里的方式来存储page table。从概念上来说，你可以认为page table是从0到2^27，但是实际上并不是这样。实际中，page table是一个多级的结构。下图是一个真正的RISC-V page table结构和硬件实现。

![](<../.gitbook/assets/image (254).png>)

==我们之前提到的虚拟内存地址中的27bit的index，实际上是由3个9bit的数字组成（L2，L1，L0）。==

前9个bit被用来索引最高级的page directory（注：通常page directory是用来索引page table或者其他page directory物理地址的表单，**但是在课程中，page table，page directory， page directory table区分并不明显，可以都认为是有相同结构的地址对应表单**）。

![](<../.gitbook/assets/image (309).png>)

一个directory是4096Bytes，就跟page的大小是一样的。==Directory中的一个条目被称为PTE（Page Table Entry）是64bits，就像寄存器的大小一样，也就是8Bytes。所以一个Directory page有512个条目。==

![](<../.gitbook/assets/image (325).png>)

==所以实际上，SATP寄存器会指向最高一级的page directory的物理内存地址，之后我们用虚拟内存中index的高9bit用来索引最高一级的page directory(注，2^9 = 512，正好可以索引到一条 PTE)，这样我们就能得到一个PPN，也就是物理page号。这个PPN指向了中间级的page directory。==

当我们在使用中间级的page directory时，我们通过虚拟内存地址中的L1部分完成索引。接下来会走到最低级的page directory，我们通过虚拟内存地址中的L0部分完成索引。==**在最低级的page directory中，我们可以得到对应于虚拟内存地址的物理内存地址。**==

![](<../.gitbook/assets/image (170).png>)

从某种程度上来说，与之前一种方案还是很相似的，除了实际的索引是由3步，而不是1步完成。这种方式的主要优点是，如果地址空间中大部分地址都没有使用，你不必为每一个index准备一个条目。

#### 举个例子，多级页表的好处

==举个例子，如果你的地址空间只使用了一个page，4096Bytes。==

![](<../.gitbook/assets/image (400).png>)

除此之外，你没有使用任何其他的地址。现在，你需要多少个page table entry，或者page table directory来映射这一个page？

**在最高级，你需要一个page directory。在这个page directory中，你需要一个数字是0的PTE，指向中间级page directory。所以在中间级，你也需要一个page directory，里面也是一个数字0的PTE，指向最低级page directory。所以这里总共需要3个page directory（也就是3 \* 512个条目）。**

![](<../.gitbook/assets/image (383).png>)

而在前一个方案中，虽然我们只使用了一个page，还是需要2^27个PTE（注，约 1GB 内存）。这个方案中，我们只需要3 \* 512个PTE（注，12KB 内存）。**所需的空间大大减少了。**这是实际上硬件采用这种层次化的3级page directory结构的主要原因。这里有什么问题吗？这部分还是很重要的。

### 学生提问

> 学生提问：既然每个物理page的PPN是44bit，而物理地址是56bit，我们从哪得到缺失的12bit？（注，这个学生嘟囔了半天，我猜他是要问这个。其实12bit直接从虚拟地址的12bit offset继承就可以了，但是可能这个问题太简单了，Frans教授似乎理解错了问题。）
>
> Frans教授：所有的page directory传递的都是PPN，对应的物理地址是44bit的PPN加上12bit的0（注，也就是page的起始地址，因为每个page directory都使用一个完整的page，所以直接从page起始地址开始使用就行）。如果我们查看这里的PTE条目，它们都有相同的格式，其中44bit是PPN，但是寄存器是64bit的，所有有一些bit是留空的。实际上，支持page的硬件在低10bit存了一些标志位用来控制地址权限。

![](<../.gitbook/assets/image (352).png>)

------

### 补充：**Page Directory 和物理地址映射原理解析**

#### **Page Directory 的含义**

- **Page Directory** 是页表（Page Table）中的一部分，用于帮助操作系统将**虚拟内存地址**转换为**物理内存地址**。
- 它的功能是将虚拟地址的**高位部分**索引到一个**中间层级的页表或实际物理页**，从而实现多级映射，优化内存的使用。

#### **Page Directory 传递 PPN 和物理地址的机制**

1. **物理页号（PPN）与页面起始地址的关系**：

   - **PPN（Physical Page Number）**：指代物理内存中的**页号**，即某一页的索引。每个物理页大小通常为 4KB（4096 字节）。
   - 一个 PPN 实际上指向了一个完整页面的**起始地址**。因为每页大小为 4KB（2122^{12}212 字节），其地址的**低12位**始终为 0。因此，只需存储 44 位的 PPN，加上 12 位的 0，即可确定物理地址的**页面起始位置**。

2. **如何传递 PPN**：

   - **Page Directory** 存储的是 PPN。每次经过一个层级的页表查找，都会找到一个新的 PPN，这个 PPN 指向下一级的 **Page Directory** 或**实际数据页**。

   - 由于 PPN 只指向页面的

     起始位置

     （而不是页面内的某个偏移地址），因此只需将低12位填充为 0。例如：

     - 如果 PPN 是 `0x0000000001234`（44位），对应的物理地址为：
       **`0x0000000001234000`**（补上12位 0，作为页的起始地址）。

3. **Page Directory 的用途**：

   - 每一个 Page Directory 占用**4KB 的页面大小**，并存储**512 个条目**（每条 PTE 8 字节，512 × 8 = 4096 字节）。
   - 每个**PTE（Page Table Entry）** 存储一个 PPN（指向下一级 Page Directory 或实际物理页）。
   - 这种设计使得查找效率更高，并且未使用的虚拟地址无需对应实际物理内存，节省了内存。

#### **总结**

这句话描述的是**多级页表系统**的工作机制。在这个系统中，Page Directory 是由多个层级组成的目录表，每次查找时都使用虚拟地址的一部分（如9位）作为索引，获取一个 PPN。这个 PPN 指向下一级目录或物理页的**起始地址**（其低12位为 0）。通过这种机制，虚拟地址到物理地址的转换能够有效地完成，同时减少内存占用和地址查找的复杂性。

------



### 保留字段10bits

> **如果你把44bit的PPN和10bit的Flags相加是54bit，也就是说还有10bit未被使用，这10bit被用来作为未来扩展。比如说某一天你有了一个新的RISC-V处理器，它的page table可能略有不同，或许有超过44bit的PPN。**如果你看下面这张图，你可以看到，这里有10bit是作为保留字段存在的。

![](<../.gitbook/assets/image (391).png>)

### 补充：**三级页表结构分析（虚拟地址到物理地址的转换过程）**

现代计算机系统为了在**虚拟内存和物理内存之间**高效映射地址，采用了**层次化的页表结构**。这里我们分析描述的三级页表机制，解释虚拟地址的索引流程和存储优化原理。

#### **三级页表结构概述**

- 虚拟地址

  被分为3部分（L2、L1、L0），每个部分为9位：

  - **L2**（最高级索引）：指向**最高级页目录**（Page Directory）。
  - **L1**（中间级索引）：指向**中间级页目录**。
  - **L0**（最低级索引）：指向**最低级页目录**，最终获取对应的物理页号（PPN）。

每级页目录（Page Directory）大小为**4KB（4096字节）**，与每个物理页的大小相同，每个条目（Page Table Entry，PTE）为**64位（8字节）**，因此一个页目录包含**512个条目**。

#### **地址转换流程**

1. **SATP寄存器指向最高级页目录的物理地址**：
   - SATP（Supervisor Address Translation and Protection）寄存器保存最高级页目录的物理地址，作为三级索引的入口。
2. **第一级索引（L2 部分）**：
   - 从虚拟地址的**高9位**读取 L2 部分（虚拟地址的第一个9-bit段），用于在最高级页目录中找到对应的**PTE**。
   - 该 PTE 的内容是指向**中间级页目录的物理页号（PPN）**。
3. **第二级索引（L1 部分）**：
   - 在中间级页目录中，通过虚拟地址的**L1 部分（9位）**找到对应的 PTE。
   - 该 PTE 指向**最低级页目录**。
4. **第三级索引（L0 部分）**：
   - 在最低级页目录中，通过**L0 部分（9位）**找到最终映射的物理页号（PPN）。
   - 虚拟地址的**页内偏移（12位 Offset）**直接拷贝到物理地址的低12位，完成最终的物理地址生成。

#### **三级页表的存储优势**

- 如果地址空间中只有一个页面被使用（即 4KB 内存），只需要：
  1. **一个最高级页目录**（1个条目指向中间级目录）。
  2. **一个中间级页目录**（1个条目指向最低级目录）。
  3. **一个最低级页目录**（1个条目指向实际使用的页面）。
- 需要的总内存为**3 × 512 PTEs × 8 字节 = 12KB**。

对比之前的单级页表方案：

- 如果没有分层结构，虚拟地址的27位索引需要存储**2^27 = 134,217,728**个条目，每个条目占8字节，总计大约 **1GB** 内存。这显然不现实。

#### **为什么采用三级页表？**

- **节省内存**：未使用的地址空间无需分配页目录或页表，大幅减少了内存开销。
- **提升性能**：只需查找有效的页目录，提高了地址转换效率。
- **灵活扩展**：支持动态分配新的页表，适应不同进程的地址需求。

#### **总结**

采用三级页表的结构极大地减少了内存占用，并且灵活支持大地址空间。每一级目录用于分段管理地址空间，通过多级索引逐步找到实际存储数据的位置。这种架构保证了系统性能和资源利用的平衡，是现代操作系统的标准做法。

------



### PTE中的Flag

接下来，让我们看看PTE中的Flag，因为它也很重要。每个PTE的低10bit是一堆标志位：

* ==第一个标志位是Valid。如果Valid bit位为1，那么表明这是一条合法的PTE，你可以用它来做地址翻译。==对于刚刚举得那个小例子（注，应用程序只用了1个page的例子），我们只使用了3个page directory，每个page directory中只有第0个PTE被使用了，所以只有第0个PTE的Valid bit位会被设置成1，其他的511个PTE的Valid bit为0。这个标志位告诉MMU，你不能使用这条PTE，因为这条PTE并不包含有用的信息。
* 下两个标志位分别是Readable和Writable。表明你是否可以读/写这个page。
* Executable表明你可以从这个page执行指令。
* User表明这个page可以被运行在用户空间的进程访问。
* 其他标志位并不是那么重要，他们偶尔会出现，前面5个是重要的标志位。

### 学生提问

> 学生提问：==我对于这里的3个page table有个问题。PPN是如何合并成最终的物理内存地址？==
>
> Frans教授：我之前或许没有很直接的说这部分（其实是有介绍的）。在最高级的page directory中的PPN，包含了下一级page directory的物理内存地址，依次类推。在最低级page directory，我们还是可以得到44bit的PPN，这里包含了我们实际上想要翻译的物理page地址，然后再加上虚拟内存地址的12bit offset，就得到了56bit物理内存地址。
>
> 
>
> Frans教授：让我来问自己的一个有趣的问题，为什么是PPN存在这些page directory中？为什么不是一个虚拟内存地址？
>
> 某学生回答：因为我们需要在物理内存中查找下一个page directory的地址。
>
> Frans教授：是的，我们不能让我们的地址翻译依赖于另一个翻译，否则我们可能会陷入递归的无限循环中。==所以page directory必须存物理地址==。那SATP呢？它存的是物理地址还是虚拟地址？
>
> 某学生回答：还是物理地址，因为最高级的page directory还是存在物理内存中，对吧。
>
> Frans教授：是的，这里必须是物理地址，因为我们要用它来完成地址翻译，而不是对它进行地址翻译。所以SATP需要知道最高一级的page directory的物理地址是什么。
>
> 学生提问： 这里有层次化的3个page table，每个page table都由虚拟地址的9个bit来索引，所以是由虚拟地址中的3个9bit来分别索引3个page table，对吗？
>
> Frans教授：是的，最高的9个bit用来索引最高一级的page directory，第二个9bit用来索引中间级的page directory，第三个9bit用来索引最低级的page directory。
>
> 学生提问：当一个进程请求一个虚拟内存地址时，CPU会查看SATP寄存器得到对应的最高一级page table，这级page table会使用虚拟内存地址中27bit index的最高9bit来完成索引，如果索引的结果为空，MMU会自动创建一个page table吗？
>
> Frans教授：不会的，MMU会告诉操作系统或者处理器，抱歉我不能翻译这个地址，最终这会变成一个page fault。如果一个地址不能被翻译，那就不翻译。就像你在运算时除以0一样，处理器会拒绝那样做。
>
> 学生提问：我想知道我们是怎么计算page table的物理地址，是不是这样，我们从最高级的page table得到44bit的PPN，然后再加上虚拟地址中的12bit offset，就得到了完整的56bit page table物理地址？
>
> Frans教授：我们不会加上虚拟地址中的offset，这里只是使用了12bit的0。所以我们用44bit的PPN，再加上12bit的0，这样就得到了下一级page directory的56bit物理地址。这里要求每个page directory都与物理page对齐（也就是page directory的起始地址就是某个page的起始地址，所以低12bit都为0）。

这些都是很好的问题，你们在page table实验中都会遇到这些问题，现在问出来很好。

------



### 补充：**虚拟内存到物理内存地址的翻译：三级页表与PPN的作用分析**

#### **虚拟内存地址中的27位与3级页表的索引过程**

- 一个虚拟内存地址的27位索引被分为3段，每段各9位：
  - **L2**：最高级页目录（Page Directory）。
  - **L1**：中间级页目录。
  - **L0**：最低级页目录。

CPU根据**SATP寄存器**指向的最高级页目录，从物理内存中的这个目录开始，逐级查找，完成地址翻译。

#### **PPN（Physical Page Number）在页表中的作用**

1. **PPN 在页目录中的使用**：
   - 每一级目录存储的**PTE（Page Table Entry）\**是一个\**PPN**。该 PPN 指向下一层页目录的起始物理地址，直到最低级页目录指向实际的数据页。
   - 为什么存储的是物理地址（PPN），而不是虚拟地址？
     - 因为翻译过程本质上是将虚拟地址映射到物理地址。存储虚拟地址会导致递归依赖（需要再翻译一次），从而陷入无限循环。
     - **PPN 提供了确定的物理位置**，避免了循环问题。
2. **物理地址的计算**：
   - 每一级 PPN 的低12位**被补0**（因为每个页对齐到 4KB 的边界），确保页面的起始地址与 PPN 对齐。
   - **完整物理地址** = **44位 PPN** + **12位补0**。这样形成**56位的物理地址**，用于找到下一层页目录或数据页。

#### 三级索引的流程

1. **从 SATP 获取最高级页目录地址**：
   - SATP寄存器保存的物理地址指向**最高级页目录**的起始地址（PPN + 12位补0）。
2. **使用虚拟地址中的 L2 部分（最高9位）进行索引**：
   - 查找到**最高级页目录**中的一个 PTE，它的值是指向**中间级页目录的 PPN**。
3. **在中间级页目录中使用 L1 部分（中间9位）索引**：
   - 找到 PTE，指向**最低级页目录**的物理地址。
4. **在最低级页目录中使用 L0 部分（最低9位）索引**：
   - 最后一级 PTE 中存储的 PPN 指向实际的物理页。
5. **计算最终物理地址**：
   - 使用最低级页目录返回的 PPN，并结合虚拟地址的**12位页内偏移（Offset）**，形成完整的**物理地址**。

#### **地址无法翻译时：Page Fault 的处理**

- 如果某一级目录的 PTE 为空（即地址未映射），**MMU 不会自动创建页表**。此时，它会抛出**Page Fault 异常**，通知操作系统来处理未映射的地址。

#### **总结**

这个过程展示了为什么每一级页目录都存储**PPN（物理页号）**而不是虚拟地址：存储物理地址可以确保翻译过程的确定性，避免递归循环。同时，通过三级页表结构减少了未使用地址的占用，提高了内存的使用效率。最终的物理地址是通过每级目录的 PPN 与 12 位偏移组合得到，确保数据访问的正确性和性能优化。

------

### **为什么采用 L2、L1、L0 的三级页表设计？**

采用多级页表结构（如**三级页表：L2 -> L1 -> L0**）是一种解决**大规模地址空间管理**的有效方法。下面详细分析这种设计背后的原因。

### **1. 降低内存占用**

- **单级页表的开销过大**：
  如果使用**单级页表**，对于 64 位地址空间（假设每页 4KB），需要存储的页表条目是 2^{44}（大约 17 万亿个条目）。每个 PTE（Page Table Entry）占 8 字节，因此需要约 140TB 内存用于页表，非常不现实。
- **多级页表减少内存浪费**：
  - 三级页表将地址空间**按需分配**。如果某些区域未使用，则无需分配对应的中间页表和条目。例如，只使用一个页面时，只有少量页目录和页表存在，而其他未用空间不会占用内存。这极大减少了内存占用。

### **2. 支持更大的地址空间**

- **64 位系统的地址空间非常大**：
  一个 64 位系统可以寻址 2^{64}264 字节地址空间，而实际内存远达不到这个规模。通过三级结构，可以有效地分配不同部分的地址空间，按需管理内存资源。
- **层级结构适应动态需求**：
  当进程需要更多内存时，操作系统可以动态创建和分配页表，而不需要在一开始就预留全部地址空间。

### **3. 提升查找效率**

- **分段查找提高性能**：
  多级页表通过将地址的查找过程分为多个小步骤，降低了每次查找的复杂度。每次查找一个 9 位段，进入下一级页表。这样分级管理的结构也有助于分配内存时的定位。
- **缓存和局部性原理**：
  由于访问地址往往集中在某些区域，多级页表的部分内容可以缓存在 TLB（Translation Lookaside Buffer）中，提高地址转换效率。

### **4. 避免不必要的资源开销**

- 按需加载的灵活性：
  - 多级页表使操作系统只在必要时分配中间和最低级页表。这种设计减少了空闲地址空间所需的管理成本。
  - 如果某个地址区域从未被使用，该路径上的页表就不会被分配，从而减少了资源浪费。

### **5. 确保地址映射的确定性**

- **每级页表只存储物理地址**：
  在地址转换过程中，页表的每级条目都指向物理地址（PPN）。这种设计避免了递归依赖，确保每个页表查找的结果明确指向下一级页表或最终的物理页面。

### **总结：三级页表设计的优势**

1. **内存节省**：减少了未使用地址空间的内存浪费。
2. **扩展性**：支持大地址空间并允许按需分配页表。
3. **查找效率**：分层管理降低了每次查找的开销，并利用缓存优化性能。
4. **确定性和安全性**：每一级页表直接指向物理地址，确保转换过程无二义性。

因此，采用多级页表设计是为了在**内存使用效率、性能、扩展性和管理复杂度**之间取得平衡。



------

### ==**为什么高级页表可以不分配？它们未被分配时的状态如何处理？**==

多级页表结构的设计目标之一是**减少内存开销**，特别是针对未使用的虚拟地址空间。这涉及到如何有效管理高层级页表（如 L2 和 L1 页表）在不分配时的处理方式。以下是详细分析。

------

#### **1. 页表中的“空洞”如何处理**

当一个高层级页表的某个条目（PTE）未指向下一级页表时，操作系统通常在**该条目中填充一个特殊的标志位**，指示该地址未被映射。通常做法包括：

- **填充 0**：表示该条目无效，未分配任何下一级页表或页面。这是最简单的做法，0 值会被 MMU 识别为**无效地址**。
- **使用标志位（Valid/Invalid Bit）**：页表条目中通常包含一个有效位（Valid Bit）。如果该位为 0，表示该条目未映射，**MMU 会忽略它，并引发 Page Fault**。

------

#### **2. 未映射地址与 Page Fault**

- 当 CPU 请求一个虚拟地址，而该地址在**高层级页表的 PTE** 中标记为无效时，MMU 会无法完成翻译。
- Page Fault：MMU 立即发出 Page Fault 异常，并通知操作系统。操作系统会根据需要执行以下操作：
  1. **分配新的页表或页面**：如果这是一个合法的访问请求，系统将分配内存并更新 PTE。
  2. **终止进程**：如果访问是非法的，操作系统会终止相关进程。

------

#### **3. 高级页表条目填充 0 的原理**

1. **无需提前分配全部页表**：
   - 如果某个地址范围未使用，那么对应的高层页表条目只需填充 0（或将有效位设为 0）。
   - 这确保了未使用的地址不会占用任何物理内存，从而节省内存。
2. **层级查找中的优化**：
   - 在查找虚拟地址时，如果 MMU 在最高层级页表的条目中发现一个 0 或无效条目，它会立即停止查找，并抛出 Page Fault，而无需继续深入其他层级。

------

#### **4. 为什么这样设计能节省资源**

- ==**按需分配内存**：操作系统只在需要时创建和分配页表，因此空闲地址空间不会浪费内存。==
- **灵活扩展**：当进程需要更多虚拟内存时，可以逐级动态分配页表，避免一次性占用大量资源。

#### **5. 总结**

多级页表的高层级目录条目在不使用时，通常会填充 0 或将**有效位设置为无效**。这确保了只有必要时才会分配下一级页表和物理页面，从而**大幅减少未使用地址空间的管理成本**。这种设计是现代操作系统内存管理的重要优化，使系统具备更高的灵活性和性能。

------



### ==**按需分配内存：减少未使用地址空间的内存浪费**==

**按需分配内存**（On-Demand Memory Allocation）指的是，操作系统只在**进程实际访问某个地址**时，才会**创建并分配页表和物理内存**。这种机制避免了为未使用的虚拟地址空间提前分配内存，从而提升了系统的资源利用效率。

#### **按需分配的具体过程**

1. **初始化时不分配页表**：
   - 当一个进程被创建时，操作系统并不会为整个虚拟地址空间立即建立完整的页表。只有当进程尝试访问某个虚拟地址时，才会触发相应的操作。
2. **Page Fault 触发页表创建**：
   - 如果进程访问一个未映射的虚拟地址（例如访问一个未初始化的变量），CPU 会通过**MMU**（内存管理单元）发现当前页表条目为空，从而触发 **Page Fault** 异常。
   - 操作系统在捕获该异常后，为该虚拟地址分配一个新的页表，并且映射对应的物理内存。
3. **避免不必要的内存占用**：
   - 未被访问的虚拟地址空间不会占用内存，这减少了对物理内存的浪费。即使某个进程声明了较大的地址空间（例如 1GB），只有真正使用的部分会被映射到物理内存。

#### **按需分配的优点**

- **节省内存**：只有被访问的虚拟地址才会分配页表和物理内存。
- **提升系统性能**：减少了不必要的内存初始化操作，将资源集中用于活跃的任务。
- **灵活性**：进程可以动态扩展或缩减使用的内存，无需预留大块空间。

#### **按需分配的例子**

假设一个程序声明了一个 1GB 的数组，但只访问了其中的 4KB。在这种情况下：

- 操作系统只会为这 4KB 分配物理内存和页表。
- 其他未访问的部分不会占用内存，也不会在页表中创建条目。

#### **总结**

按需分配内存的设计使得操作系统能够更加高效地管理资源，特别是在大地址空间中。通过只在需要时创建和分配页表，操作系统避免了不必要的内存占用。这种机制使得系统可以在内存有限的情况下，支持更多的进程并提升整体性能。

------

### ==补充：多级页表是只看最低级，只有最低级才会转换到最后的物理内存地址吗？==

### **多级页表中的地址转换：每一级的作用与最低级页表的转换过程**

#### **多级页表中的每一级都有作用吗？**

是的，多级页表的每一级都参与地址转换，但**只有最低级页表**（如三级结构中的 **L0**）最终会提供指向**物理内存页面的地址**。以下是每一级的具体作用：

1. **L2（最高级页目录）**：
   - 存储指向**中间级页目录**的 PPN（物理页号）。
   - 通过虚拟地址的最高 9 位（L2 部分）在这一目录中找到指向下一层的 PPN。
2. **L1（中间级页目录）**：
   - 存储指向**最低级页目录**的 PPN。
   - 通过虚拟地址的中间 9 位（L1 部分）来索引这一目录。
3. **L0（最低级页目录）**：
   - 存储指向**实际物理内存页面**的 PPN。
   - 通过虚拟地址的最低 9 位（L0 部分）找到对应的物理页面。
   - **这一层的 PPN**（加上虚拟地址中的 12 位偏移量）形成最终的**物理地址**。

#### **最低级页表如何完成物理地址转换？**

1. **查找最低级页目录中的 PTE**：
   - 虚拟地址的最低 9 位用于在**L0 页目录**中索引出一个**Page Table Entry (PTE)**。
   - 这个 PTE 存储了指向物理页面的 PPN（44 位）。
2. **物理地址的生成**：
   - 该 PPN 指向的物理页面的**起始地址**。最后将虚拟地址中的**页内偏移（12 位）\**加到 PPN 指定的地址上，形成完整的\**56 位物理地址**。

#### 为什么只有最低级页表指向物理页面？

- **地址空间分段管理**：
  - 多级页表通过分层结构，将虚拟地址逐级拆解成段（L2、L1、L0），每段对应于不同的索引级别。
  - 这种分层设计允许按需分配地址空间，并使得地址映射更加灵活和高效。
- **减少内存占用**：
  - 每一级目录只负责**指向下一级页目录**或**实际物理页面**。只有最低级页表中的条目才会映射到实际的物理页面，以节省内存。
- **避免递归依赖**：
  - 每个目录条目存储的是**物理地址（PPN）**，确保每一级索引过程明确，最终只有最低级页目录中的 PTE 能够指向实际的数据页。

#### **总结**

在多级页表结构中，**每一级都参与了地址的逐级映射**，但只有**最低级页表（如 L0 页表）\**会最终指向\**物理内存页面**。这个结构不仅优化了内存管理，还支持按需分配资源，避免了地址空间的浪费。



------



# 4.3 页表（Page Table）详细总结

## 一、页表实现地址空间的原理

### 1. 页表的核心概念

- **页表**实现虚拟地址和物理地址的映射，是创建地址空间的关键。
- 页表由**MMU（Memory Management Unit）\**管理，MMU将\**虚拟地址**转换为**物理地址**。

### 2. 虚拟地址的处理流程

- CPU执行指令时，所有地址都是**虚拟地址**。
- **MMU**读取虚拟地址，并在页表中查找对应的物理地址。

- 将找到的物理地址用于数据存取。

## 二、页表的存储与切换

### 1. 页表的存储位置

- 页表存储在**内存中**，而不是MMU内部。
- **SATP寄存器**保存页表的物理地址，用于指示MMU如何访问页表。

### 2. 进程切换中的页表管理

- **操作系统**切换进程时，更新SATP寄存器的值，指向新进程的页表。
- 每个进程都有独立的页表，因此相同的虚拟地址可以映射到不同的物理地址，实现**隔离性**。

## 三、页表的层次结构和粒度

### 1. 为什么使用页为单位

- 为了避免为每个地址单独创建条目，**页表以4KB为单位**进行管理。
- 虚拟地址划分：
  - **Index**：用于查找页的编号。
  - **Offset**：指定页内的具体字节。

### 2. 页表的多级结构

- RISC-V的页表采用**3级层次结构**，减少内存占用。

- 虚拟地址的**27bit index**拆分为3个9bit部分（L2, L1, L0），分别用于索引不同级别的页表。

------

## 四、RISC-V的地址空间设计

### 1. 地址空间大小

- **虚拟地址**为64位，但使用了**39位**，限制地址空间为**512GB**。
- **物理地址**为56位，支持最大**2^56字节**的内存。

### 2. PTE（Page Table Entry）格式

- 每个PTE占用8字节（64位），其中**44位用于存储物理页号（PPN）**。

### 3. 页表的灵活性

- 页表采用层次化结构，使得不需要使用的地址空间无需占用大量内存。

## 五、PTE的标志位及访问控制

### 1. PTE的标志位

- **Valid**：标识PTE是否有效。
- **Readable / Writable / Executable**：控制页是否可读、写或执行。
- **User**：指示页是否可以被用户空间进程访问。

## 六、页表翻译与操作示例

### 1. 页表翻译过程

1. **SATP寄存器**指向最高级页表的物理地址。
2. 虚拟地址的**高9bit**索引到L2页表，获取下一级页表的物理地址。
3. **中间9bit**索引到L1页表。
4. **最低9bit**索引到L0页表，获取目标页的PPN。
5. 最终将PPN与虚拟地址的**12bit offset**合并，生成完整的物理地址。

### 2. 未找到页表条目的处理

- 如果某级页表不存在对应条目，MMU会报告**page fault**，并交由内核处理。

------

## 七、总结与思考

### 1. 页表的作用与实现

- **页表提供隔离性**，使每个进程拥有独立的地址空间，防止内存篡改。
- 页表采用多级结构，减少内存占用。

### 2. RISC-V地址空间的设计考虑

- **虚拟地址和物理地址**大小设计基于未来内存需求的预测。
- **56位物理地址**支持大规模内存，但目前主板还不支持如此大的容量。

### 3. 实验中的重点

- 理解页表的结构和翻译过程对于实验非常重要。
- 学生在实验中会遇到**PTE的管理和page fault的处理**，这是操作系统设计的核心部分。

本节课详细讲解了**页表的多级结构、地址转换过程和RISC-V中的实现细节**。通过对页表的深入理解，我们可以掌握如何通过硬件和软件协同，实现虚拟地址到物理地址的高效映射。这些知识为后续的**page table实验**打下了坚实基础。

------



### 补充：在MIPS汇编语言中，`sd $7, (a0)` 是一个**存储指令**，其具体含义如下：

1. **`sd` 指令**：
   - `sd` 代表 **store double word**，用于将64位数据从寄存器存储到内存中。
   - 在MIPS64架构中，**double word**表示64位数据。
2. **`$7`**：
   - 这是一个寄存器，包含要存储的数据。
   - 在这里，`$7`表示第7个寄存器（通常是通用寄存器）。
3. **`(a0)`**：
   - 这里的 `a0` 是一个寄存器，通常用于传递参数，表示**内存地址**或**地址基准**。
   - `(a0)` 的意思是取寄存器 `a0` 中存储的地址，然后将数据存储到这个地址位置。

#### **整体解释**

`sd $7, (a0)` 指的是：
将 `$7` 寄存器中的64位数据存储到 **寄存器 `a0` 指定的内存地址** 中。

#### **举例**

假设：

- `$7` 中存有数据 `0x1234567890ABCDEF`。
- `a0` 中存有地址 `0x10010000`。

执行 `sd $7, (a0)` 后：

- 内存地址 `0x10010000` 开始的64位位置将被填入 `0x1234567890ABCDEF`。

#### **补充说明**

- 这是在 MIPS64 体系中的指令。在 MIPS32 中，类似的指令是 `sw`（store word），用于存储32位数据。
- 如果你还涉及偏移量存储的情况，如 `sd $7, 8(a0)`，则表示将 `$7` 中的数据存入 `a0` 的地址**加上偏移量8字节**的内存地址中。

### 补充：**寄存器的作用**

寄存器是**中央处理器（CPU）内部的高速存储单元**，用于存储数据、指令或地址信息。在计算机体系结构中，寄存器的主要作用是**加快数据的访问速度**，因为与主存（如RAM）相比，寄存器的读写速度极快。

#### **寄存器的主要功能**

1. **临时存储数据**：
   - CPU在执行指令时，需要频繁使用一些中间数据（例如计算的部分结果）。寄存器提供一个临时位置来存储这些数据，避免频繁访问内存，从而提升速度。
2. **存储地址**：
   - 在某些情况下，寄存器会保存内存地址，用于指向需要访问的数据或指令的位置。例如，在MIPS中，`a0` 可以存储一个地址。
3. **控制指令执行**：
   - CPU执行程序需要寄存器存储程序计数器（PC），以指示下一条指令的地址。控制类寄存器也帮助管理中断、状态等。
4. **传递参数和返回值**：
   - 在MIPS等RISC架构中，寄存器（如 `$a0 - $a3`）常用来存储传递给函数的参数，而 `$v0` 常用于存储返回值。
5. **执行算术和逻辑运算**：
   - 大多数算术或逻辑指令都直接在寄存器之间执行，避免访问缓慢的内存。例如，`add $t0, $t1, $t2` 将寄存器 `$t1` 和 `$t2` 的值相加，并存储在 `$t0` 中。

#### **常见寄存器类型**

1. **通用寄存器（General Purpose Registers, GPRs）**：
   - 存储数据或地址，程序可以灵活使用这些寄存器。例如，在MIPS架构中有 `$t0 - $t9` 和 `$s0 - $s7` 等。
2. **程序计数器（PC，Program Counter）**：
   - 存储即将执行的指令的内存地址。
3. **状态寄存器（Status Registers）**：
   - 存储CPU的状态信息（如中断状态、算术运算的溢出标志等）。
4. **堆栈指针寄存器（SP，Stack Pointer）**：
   - 指向栈的顶端，用于管理函数调用中的局部变量和返回地址。
5. **浮点寄存器（FPRs，Floating-Point Registers）**：
   - 专门用于存储和处理浮点数。

#### **寄存器 vs. 内存**

| **特性**        | **寄存器**                 | **内存（RAM）**         |
| --------------- | -------------------------- | ----------------------- |
| **访问速度**    | 极快                       | 相对较慢                |
| **容量**        | 极小（几十到几百个寄存器） | 较大（GB级）            |
| **用途**        | 存储临时数据或地址         | 存储程序和数据          |
| **与CPU的距离** | 在CPU内部                  | 在CPU外部，通过总线连接 |

#### **总结**

寄存器是CPU执行指令时的重要组成部分，负责存储临时数据、地址、指令计数等关键信息。由于寄存器的访问速度极快，计算机系统中的大多数运算和数据操作都会优先在寄存器中进行，减少对内存的访问，从而提升整体性能。

------



### 补充:**内存（Memory）简介**

内存（Memory），也称为**主存**或**随机存取存储器（RAM, Random Access Memory）**，是计算机系统中的一种高速存储器，用来存储正在运行的**程序**和**数据**。内存充当了CPU和磁盘之间的临时数据存储桥梁，因为它的读写速度远远快于硬盘等外部存储设备。

#### **内存的主要作用**

1. **存储正在运行的程序和数据**
   - 当计算机运行程序时，程序的指令和数据会从硬盘加载到内存中，供CPU快速读取和执行。
2. **与CPU协同工作**
   - CPU直接从内存中取指令和数据。因为内存的访问速度比硬盘快，减少CPU的等待时间，从而提高性能。
3. **临时存储**
   - 内存的数据在断电后会**丢失**，因此它用于存储临时数据。永久存储则依赖于硬盘、SSD等存储设备。

#### **内存的分类**

1. **随机存取存储器（RAM）**
   - **动态RAM（DRAM）**：常用作计算机主内存。需要不断刷新数据，但容量较大、价格较低。
   - **静态RAM（SRAM）**：速度比DRAM快，但价格贵、容量小。多用于CPU缓存。
2. **只读存储器（ROM）**
   - ROM是一种存储永久数据的内存，数据在出厂时写入。常用于存储固件或系统启动代码（BIOS）。
3. **缓存（Cache）**
   - 存储频繁使用的数据和指令，在CPU和RAM之间充当缓存，进一步提高访问速度。

#### **内存的结构和工作方式**

内存是按**地址**组织的，每个地址对应存储一定大小的数据（通常是字节）。CPU通过**地址总线**找到需要的数据，并通过**数据总线**读取或写入数据。

#### **内存访问示例**

假设：

- 程序要读取变量 `x` 的值，该变量的地址为 `0x1000`。
- CPU会发出指令从地址 `0x1000` 中读取数据，并将其传给寄存器。

#### 内存的作用和CPU的关系

1. **加载程序**：当我们打开一个应用程序时，操作系统会将该程序从硬盘加载到内存中。
2. **缓存数据**：当我们处理文件时，数据会从硬盘先加载到内存，供程序使用。
3. **减少I/O等待**：内存的高速特性减少了CPU的等待时间。

#### **内存的特点**

| **特性**       | **内存（RAM）** | **硬盘/SSD**   |
| -------------- | --------------- | -------------- |
| **速度**       | 快（纳秒级）    | 慢（毫秒级）   |
| **容量**       | 较小（GB级）    | 较大（TB级）   |
| **数据持久性** | 断电后数据丢失  | 断电后数据保留 |
| **成本**       | 比硬盘贵        | 比RAM便宜      |

#### **常见问题：内存不足与虚拟内存**

1. **内存不足**
   - 当主存（RAM）用完时，计算机会变慢，因为操作系统必须将数据交换到硬盘上的**交换空间**（swap）。
2. **虚拟内存**
   - 当物理内存不足时，操作系统会将部分内存映射到硬盘，作为虚拟内存。这虽然能暂时解决内存不足的问题，但速度较慢。

#### **总结**

内存是计算机系统中不可或缺的组成部分，负责临时存储数据和程序，以便CPU快速访问。它在速度和容量上介于寄存器和硬盘之间，为系统的正常运行提供了关键支持。虽然内存的速度较快，但断电后数据会丢失，因此重要数据需要保存在持久性存储（如硬盘或SSD）中。

------



### ==补充：**用户态通过系统调用进入内核态的详细过程**==

在计算机系统中，**系统调用（System Call）\**是用户程序请求操作系统内核执行特权操作的机制，比如文件操作、网络通信或内存分配。这一过程需要\**CPU从用户态切换到内核态**，因为普通用户程序没有足够的权限直接操作硬件资源。

#### **用户态到内核态的切换过程：详细步骤**

1. **用户程序发起系统调用**

   - 用户程序通过**库函数**调用系统调用接口（如 `read()`、`write()`）。
   - 在 Linux 中，glibc库函数如 `read()` 实际上封装了系统调用，通过 **`ecall`** 或 **中断指令** 触发系统调用。

2. **执行陷入（Trap）指令**

   - 系统调用通过

     陷入（Trap）指令

     进入内核态。

     - 在 x86 架构中，常用 `int 0x80` 或 `syscall` 指令。
     - 在 RISC-V 架构中，则使用 **`ecall`（Environment Call）** 指令。

3. **CPU模式切换：从用户态到内核态**

   - 执行 `ecall` 或 `syscall` 后，CPU立即**从用户态切换到内核态**。
   - 此时，CPU会保存当前程序的**上下文**（如寄存器内容、程序计数器等），以便系统调用返回后能恢复到原来的状态。

4. **跳转到系统调用的入口函数**

   - 系统调用指令执行后，CPU会跳转到内核中的

     系统调用表（System Call Table）。

     - 这是一个内核中的映射表，包含所有系统调用编号及对应的处理函数。

   - 根据系统调用编号，找到对应的**内核处理函数**并跳转执行。

5. **执行内核代码**

   - 在内核态中执行系统调用对应的代码。例如：
     - 如果是 `read()` 系统调用，内核会读取指定文件的数据。
     - 如果是 `write()`，内核会将数据写入设备或文件中。

6. **系统调用返回结果**

   - 系统调用完成后，内核会将结果存入用户程序可以访问的寄存器（如 x86 的 `rax` 或 RISC-V 的 `a0` 寄存器）。
   - CPU准备切换回用户态。

7. **CPU切换回用户态**

   - 内核恢复被保存的上下文，将控制权交还给用户程序，并**切换回用户态**。
   - 现在，用户程序可以继续执行，并使用系统调用返回的结果。

#### **`ecall` 的具体使用：RISC-V 架构中的例子**

在 RISC-V 架构中，`ecall` 是触发系统调用的指令，详细过程如下：

1. **用户程序调用系统调用**
   通过汇编代码触发系统调用：

   ```
   li a7, 64        # 系统调用编号（如 write()）
   li a0, 1         # 第一个参数（文件描述符）
   la a1, message   # 第二个参数（要写入的数据地址）
   li a2, 13        # 第三个参数（数据长度）
   ecall            # 触发系统调用
   ```

   - `a7` 寄存器存储系统调用的编号。
   - `a0`、`a1`、`a2` 等寄存器存储系统调用的参数。

2. **进入内核态**

   - 执行 `ecall` 后，CPU切换到内核态，并根据 `a7` 中的编号找到对应的系统调用处理函数。

3. **内核执行系统调用逻辑**

   - 在内核态中执行写入操作，将数据写入到文件或设备。

4. **返回用户态**

   - 系统调用完成后，内核通过 `sret` 指令返回用户态。

#### **总结：系统调用中的`ecall`如何工作**

- **`ecall`** 是 RISC-V 架构中的系统调用指令，类似于 x86 的 `syscall`。它通过陷入机制将CPU从**用户态切换到内核态**。
- CPU会从系统调用表中找到对应的内核处理函数，执行完成后再切换回用户态。
- 这种模式确保了系统的安全性：用户程序不能直接访问内核功能，而是必须通过受控的系统调用接口。

通过这种设计，**用户态程序和内核之间的隔离**确保了计算机系统的稳定和安全。

------

