# 4.5 Kernel Page Table

接下来，我们看一下在XV6中，page table是如何工作的？首先我们来看一下kernel page的分布。下图就是内核中地址的对应关系，左边是内核的虚拟地址空间，右边上半部分是物理内存或者说是DRAM，右边下半部分是I/O设备。接下来我会首先介绍右半部分，然后再介绍左半部分。

![](<../.gitbook/assets/image (345).png>)

### 主板 DRAM I/O设备

图中的右半部分的结构完全由硬件设计者决定。如你们上节课看到的一样，当操作系统启动时，会从地址0x80000000开始运行，这个地址其实也是由硬件设计者决定的。具体的来说，如果你们看一个主板，

![](<../.gitbook/assets/image (238).png>)

中间是RISC-V处理器，我们现在知道了处理器中有4个核，每个核都有自己的MMU和TLB。处理器旁边就是DRAM芯片。

![](<../.gitbook/assets/image (404).png>)

**主板的设计人员决定了，在完成了虚拟到物理地址的翻译之后，如果得到的物理地址大于0x80000000会走向DRAM芯片，如果得到的物理地址低于0x80000000会走向不同的I/O设备。**这是由这个主板的设计人员决定的物理结构。如果你想要查看这里的物理结构，你可以阅读主板的手册，手册中会一一介绍物理地址对应关系。

![](<../.gitbook/assets/image (244).png>)

![](<../.gitbook/assets/image (192).png>)

首先，地址0是保留的，地址0x10090000对应以太网，地址0x80000000对应DDR内存，处理器外的易失存储（Off-Chip Volatile Memory），也就是主板上的DRAM芯片。

==所以，在你们的脑海里应该要记住这张主板的图片，即使我们接下来会基于你们都知道的C语言程序---QEMU来做介绍，但是最终所有的事情都是由主板硬件决定的。==

### 学生提问

> 学生提问：当你说这里是由硬件决定的，硬件是特指CPU还是说CPU所在的主板？
>
> Frans教授：CPU所在的主板。CPU只是主板的一小部分，DRAM芯片位于处理器之外。是主板设计者将处理器，DRAM和许多I/O设备汇总在一起。对于一个操作系统来说，CPU只是一个部分，I/O设备同样也很重要。所以当你在写一个操作系统时，你需要同时处理CPU和I/O设备，比如你需要向互联网发送一个报文，操作系统需要调用网卡驱动和网卡来实际完成这个工作。

回到最初那张图的右侧：物理地址的分布。可以看到最下面是未被使用的地址，这与主板文档内容是一致的（地址为0）。**地址0x1000是boot ROM的物理地址，当你对主板上电，主板做的第一件事情就是运行存储在boot ROM中的代码，当boot完成之后，会跳转到地址0x80000000**，操作系统需要确保那个地址有一些数据能够接着启动操作系统。

![](<../.gitbook/assets/image (205).png>)

这里还有一些其他的I/O设备：

* PLIC是中断控制器（Platform-Level Interrupt Controller）我们下周的课会讲。
* CLINT（Core Local Interruptor）也是中断的一部分。所以多个设备都能产生中断，需要中断控制器来将这些中断路由到合适的处理函数。
* UART0（Universal Asynchronous Receiver/Transmitter）负责与Console和显示器交互。
* VIRTIO disk，与磁盘进行交互。

地址0x02000000对应CLINT，当你向这个地址执行读写指令，你是向实现了CLINT的芯片执行读写。这里你可以认为你直接在与设备交互，而不是读写物理内存。

> 学生提问：确认一下，低于0x80000000的物理地址，不存在于DRAM中，当我们在使用这些地址的时候，指令会直接走向其他的硬件，对吗？
>
> Frans教授：是的。高于0x80000000的物理地址对应DRAM芯片，但是对于例如以太网接口，也有一个特定的低于0x80000000的物理地址，我们可以对这个叫做内存映射I/O（Memory-mapped I/O）的地址执行读写指令，来完成设备的操作。
>
> &#x20;学生提问：为什么物理地址最上面一大块标为未被使用？
>
> Frans教授：物理地址总共有2^56那么多，但是你不用在主板上接入那么多的内存。所以不论主板上有多少DRAM芯片，总是会有一部分物理地址没有被用到。==实际上在XV6中，我们限制了内存的大小是128MB。==
>
> 学生提问：当读指令从CPU发出后，它是怎么路由到正确的I/O设备的？比如说，当CPU要发出指令时，它可以发现现在地址是低于0x80000000，但是它怎么将指令送到正确的I/O设备？
>
> Frans教授：你可以认为在RISC-V中有一个多路输出选择器（demultiplexer）。

### 主板上电 -> XV6启动 -> 设置虚拟地址空间

接下来我会切换到第一张图的左边，这就是XV6的虚拟内存地址空间。**当机器刚刚启动时，还没有可用的page，XV6操作系统会设置好内核使用的虚拟地址空间，也就是这张图左边的地址分布。**

因为我们想让XV6尽可能的简单易懂，所以这里的虚拟地址到物理地址的映射，大部分是相等的关系。比如说内核会按照这种方式设置page table，虚拟地址0x02000000对应物理地址0x02000000。这意味着左侧低于PHYSTOP的虚拟地址，与右侧使用的物理地址是一样的。

![](<../.gitbook/assets/image (354).png>)

所以，这里的箭头都是水平的，因为这里是完全相等的映射。

### 未被映射的Guard page->不映射->kernel stack耗尽触发page fault

除此之外，这里还有两件重要的事情：

第一件事情是，有一些page在虚拟内存中的地址很靠后，比如kernel stack在虚拟内存中的地址就很靠后。这是因为在它之下有一个未被映射的Guard page，这个Guard page对应的PTE的Valid 标志位没有设置，这样，==如果kernel stack耗尽了，它会溢出到Guard page，但是因为Guard page的PTE中Valid标志位未设置，会导致立即触发page fault，这样的结果好过内存越界之后造成的数据混乱。立即触发一个panic（也就是page fault），你就知道kernel stack出错了。==同时我们也又不想浪费物理内存给Guard page，所以Guard page不会映射到任何物理内存，它只是占据了虚拟地址空间的一段靠后的地址。

### kernel stack映射2次， 虚拟地址物理地址可以多种映射关系

同时，kernel stack被映射了两次，在靠后的虚拟地址映射了一次，在PHYSTOP下的Kernel data中又映射了一次，但是实际使用的时候用的是上面的部分，因为有Guard page会更加安全。

![](<../.gitbook/assets/image (258).png>)

这是众多你可以通过page table实现的有意思的事情之一。==你可以向同一个物理地址映射两个虚拟地址，你可以不将一个虚拟地址映射到物理地址。可以是一对一的映射，一对多映射，多对一映射。==XV6至少在1-2个地方用到类似的技巧。这的kernel stack和Guard page就是XV6基于page table使用的有趣技巧的一个例子。

第二件事情是权限。例如Kernel text page被标位R-X，意味着你可以读它，也可以在这个地址段执行指令，但是你不能向Kernel text写数据。通过设置权限我们可以尽早的发现Bug从而避免Bug。对于Kernel data需要能被写入，所以它的标志位是RW-，但是你不能在这个地址段运行指令，所以它的X标志位未被设置。（注，所以，kernel text用来存代码，代码可以读，可以运行，但是不能篡改，kernel data用来存数据，数据可以读写，但是不能通过数据伪装代码在kernel中运行）

![](<../.gitbook/assets/image (260).png>)

### 学生提问

#### 用户进程虚拟地址空间 --- 内核虚拟地址空间

> 学生提问：对于不同的进程会有不同的kernel stack吗？
>
> Frans：答案是的。每一个用户进程都有一个对应的kernel stack
>
> 学生提问：用户程序的虚拟内存会映射到未使用的物理地址空间吗？
>
> Frans教授：在kernel page table中，有一段Free Memory，它对应了物理内存中的一段地址。
>
>

![](<../.gitbook/assets/image (246).png>)

> XV6使用这段free memory来存放用户进程的page table，text和data。如果我们运行了非常多的用户进程，某个时间点我们会耗尽这段内存，这个时候fork或者exec会返回错误。
>
> 同一个学生提问：这就意味着，用户进程的虚拟地址空间会比内核的虚拟地址空间小的多，是吗？
>
> Frans教授：==本质上来说，两边的虚拟地址空间大小是一样的。但是用户进程的虚拟地址空间使用率会更低。==
>
> 学生提问：如果多个进程都将内存映射到了同一个物理位置，这里会优化合并到同一个地址吗？
>
> Frans教授：XV6不会做这样的事情，但是page table实验中有一部分就是做这个事情。真正的操作系统会做这样的工作。当你们完成了page table实验，你们就会对这些内容更加了解。

（以下问答来自这节课程结束部分，因为内容相关就移过来了）

> 学生提问：每个进程都会有自己的3级树状page table，通过这个page table将虚拟地址翻译成物理地址。所以看起来当我们将内核虚拟地址翻译成物理地址时，我们并不需要kernel的page table，因为进程会使用自己的树状page table并完成地址翻译（注，不太理解这个问题点在哪）。
>
> Frans教授：当kernel创建了一个进程，针对这个进程的page table也会从Free memory中分配出来。内核会为用户进程的page table分配几个page，并填入PTE。在某个时间点，当内核运行了这个进程，内核会将进程的根page table的地址加载到SATP中。从那个时间点开始，处理器会使用内核为那个进程构建的虚拟地址空间。
>
> 同一个学生提问：所以内核为进程放弃了一些自己的内存，但是进程的虚拟地址空间理论上与内核的虚拟地址空间一样大，虽然实际中肯定不会这么大。
>
> Frans教授：是的，下图是用户进程的虚拟地址空间分布，与内核地址空间一样，它也是从0到MAXVA。

![](<../.gitbook/assets/image (211).png>)

> 它有由内核设置好的，专属于进程的page table来完成地址翻译。

> 学生提问：但是我们不能将所有的MAXVA地址都使用吧？
>
> Frans教授：是的我们不能，这样我们会耗尽内存。大多数的进程使用的内存都远远小于虚拟地址空间。

------

## 拓展

### 补充：**对学生与教授间问题的详细分析与正确解答**

#### **1. 是否为每个进程分配一个独立的 Kernel Stack？**

#### 学生问题：

> **每个进程是否会有自己的 Kernel Stack？**

#### Frans 的回答：

- **是的**，每个用户进程都有一个对应的 **Kernel Stack**。

#### **逻辑与解答：**

- **Kernel Stack** 是每个进程切换到内核态时用于保存内核态上下文的数据结构。每个进程拥有一个独立的 Kernel Stack，是为了避免在系统调用或中断处理时多个进程的内核状态相互覆盖或干扰。
- ==**每个进程的 Kernel Stack** 只在该进程进入内核态时使用，并在进程切换到用户态后清理或保留状态，以便下一次内核调用使用。==

#### 2. 用户程序的虚拟内存会映射到未使用的物理地址吗？

#### 学生问题：

> **用户程序的虚拟内存会映射到未使用的物理地址空间吗？**

#### Frans 的回答：

- **在 kernel page table 中**确实有一段**free memory**，用于存放用户进程的页表、代码（text）和数据。

#### 逻辑与解答：

- **Free memory** 是操作系统为用户进程分配物理内存的缓冲区。==每次进程创建时，内核会从这段可用的物理内存中分配空间，并将其映射到用户虚拟地址空间。==
- **资源耗尽的情况**：当系统中的用户进程过多时，这段物理内存可能会用尽，导致系统无法再执行 `fork()` 或 `exec()` 系统调用，此时这些调用会返回错误。

#### **3. 用户与内核虚拟地址空间的比较**

#### 学生问题：

> **用户进程的虚拟地址空间比内核的虚拟地址空间小吗？**

#### Frans 的回答：

- 虽然**理论上**用户和内核的虚拟地址空间大小相同，但**用户进程的虚拟地址空间使用率通常更低**。

#### **逻辑与解答：**

- **虚拟地址空间**的最大值由架构的地址位数决定，例如 64 位系统可以使用 2^{64} 个虚拟地址。
- **用户进程与内核的虚拟地址空间**都是从地址 0 到 MAXVA，但大多数用户进程仅使用一小部分虚拟地址空间（如代码段、堆栈、数据段等）。
- 内核虽然拥有与用户相同大小的虚拟地址空间，但它主要用于管理系统资源，并映射关键的系统内存区域。

**4. 是否优化多个进程的内存映射？**

#### 学生问题：

> **如果多个进程都映射到了同一个物理位置，会进行内存合并吗？**

#### Frans 的回答：

- **XV6** 不会这样做，但其他现代操作系统会通过**内存共享和优化**来合并这些映射。

#### **逻辑与解答：**

- ==**内存共享优化**（如**写时复制，Copy-on-Write**）是现代操作系统的一项优化技术。多个进程可以共享同一份内存数据（如共享库），直到某个进程尝试写入该内存。这种技术提高了内存利用率。==
- **XV6** 是一个教学操作系统，未实现这些复杂的优化，但通过 page table 实验可以帮助学生理解这种优化的工作原理。

#### **5. 进程是否使用内核的页表完成地址翻译？**

#### 学生问题：

> **用户进程的页表是否由内核管理？是否需要使用 kernel 的页表来完成翻译？**

#### Frans 的回答：

- ==**每个进程**都有一个独立的**三级树状页表**，由内核在 Free Memory 中创建并管理。==--**逻辑视角**

#### **逻辑与解答：**

- 当内核创建进程时，会在 Free Memory 中分配该进程的页表，并在页表条目中填入对应的 PTE（Page Table Entry）。
- **SATP寄存器**会指向该进程的根页表。当进程切换时，CPU 会加载进程的页表地址到 SATP 中，这样 MMU（内存管理单元）就能使用该页表完成地址转换。

#### **6. 用户进程的虚拟地址空间如何与内核地址空间比较？**

#### 学生问题：

> **内核为进程腾出了一部分自己的内存，这会影响内核的地址空间吗？**

#### Frans 的回答：

- 虽然进程会占用一些内核分配的内存，但两者的**虚拟地址空间都是从 0 到 MAXVA**。每个进程都有自己的页表结构完成地址翻译。

#### **逻辑与解答：**

- **内核为每个进程分配物理内存和页表**，但进程的虚拟地址空间和内核地址空间是相互独立的。即使虚拟地址空间的范围相同，物理内存的使用情况也不同。
- 进程之间的虚拟地址空间也彼此隔离，互不干扰。

#### **7. 为什么不能使用所有的 MAXVA 地址？**

#### 学生问题：

> **为什么不能将所有的 MAXVA 地址都使用？**

#### Frans 的回答：

- 虽然理论上每个进程都有 2^{64} 的虚拟地址空间，但**大多数进程实际使用的内存远远小于虚拟地址空间**。

#### **逻辑与解答：**

- ==**虚拟地址空间大于物理内存**是为了支持地址空间隔离和按需分配。每个进程只使用一部分虚拟地址，并且未使用的部分不会映射到物理内存，从而节省资源。==
- 如果所有虚拟地址都映射到物理地址，系统将会耗尽内存，导致崩溃或无法继续分配新资源。

#### **总结：正确答案整理**

1. **每个进程有自己的 Kernel Stack**：是的，内核为每个进程分配一个 Kernel Stack，用于内核态操作。
2. **用户虚拟地址是否映射到未使用的物理地址？**：不是，只有被使用的虚拟地址才会映射到物理地址，未使用的地址不会占用物理内存。
3. **用户和内核虚拟地址空间是否相同？**：理论上相同，但用户进程的实际使用率通常较低。
4. **多个进程共享物理内存时是否合并？**：XV6 不会进行合并，但现代操作系统支持这种优化（如共享库的写时复制）。
5. **用户页表由谁管理？**：用户进程的页表由内核分配和管理，但每个进程有独立的页表，加载到 SATP 寄存器中供 MMU 使用。
6. **虚拟地址空间和物理内存的关系**：虚拟地址空间远大于物理内存，但只在需要时分配物理内存，以节省资源。

------

### **为什么需要 Free Memory？**

**Free Memory** 是指系统中**尚未分配给任何进程或内核模块**的内存。这段内存被预留出来，以便动态分配给用户进程、内核数据结构（如页表）、缓存等各种需要临时内存资源的任务。下面详细解释为什么需要这种 **free memory** 机制。

#### **1. 动态分配内存以应对变化需求**

- **进程和页表管理**：当用户进程被创建或内存需要扩展时，系统需要为进程分配物理内存。如果没有 Free Memory，那么进程无法创建或无法扩展内存。
- **按需内存分配**：进程可能不会一次性使用所有的内存。因此，系统只在需要时将 Free Memory 分配给进程，避免不必要的资源浪费。

#### **2. 预防碎片化，提升系统性能**

- **避免碎片化**：系统会预留一部分内存为 Free Memory，用于在需要时整块分配给新进程或缓存，以减少内存碎片的产生。
- **提升性能**：当内核需要分配页表或缓存时，预留的 Free Memory 可以快速满足请求，减少内存分配的延迟。

#### **3. 处理系统调用和异常情况**

- **Page Fault 处理**：当进程访问未映射的虚拟地址时，会触发 Page Fault 异常，系统需要从 Free Memory 中分配一个物理页面并更新页表。
- **fork 和 exec 的支持**：这些系统调用需要为新进程分配新的内存空间。如果没有 Free Memory，则系统无法响应这些调用。

#### **4. 支持缓存和 I/O 加速**

- **内存缓存**：现代操作系统使用 Free Memory 作为磁盘和 I/O 缓存，以提高数据访问速度。当缓存不再需要时，这部分内存会被释放回 Free Memory 池。
- **文件系统的缓冲区**：文件的读写操作也依赖 Free Memory 来提供缓冲，加快 I/O 处理。

#### **5. 系统稳定性和故障恢复**

- **预留应急内存**：Free Memory 是系统稳定性的重要保障。如果所有内存都被占用，当出现紧急情况（如系统需要处理错误或调度新进程）时，系统将无法继续运行。
- **内核任务的内存需求**：某些内核任务在运行时需要动态分配内存，如页表扩展、文件系统管理等。预留 Free Memory 可以确保这些任务不会因内存不足而失败。

#### **6. 内核和用户进程的分离**

- **隔离内核和用户进程**：Free Memory 既可以用于内核分配，也可以用于用户进程。这种隔离保证了用户进程不会随意占用内核的关键内存区域，提升系统安全性。

#### **总结**

Free Memory 的存在是现代操作系统的必要机制，它提供了：

1. **动态内存管理**：满足进程和内核在运行时的内存需求。
2. **缓存与优化**：支持系统性能的提升。
3. **系统稳定性**：在异常情况下提供应急资源。

通过 Free Memory，系统能够更好地应对突发的内存需求，并在保证性能和稳定性的同时，减少资源浪费。

------

### ==**为什么需要内核虚拟地址空间？用户进程虚拟地址和内核虚拟地址空间的区别**==

现代操作系统采用**虚拟内存管理**，为每个进程分配独立的虚拟地址空间。然而，操作系统还必须维护一个**内核虚拟地址空间**，与用户进程的虚拟地址空间**相互独立**，但在某些部分也会共享。下面详细分析为什么内核和用户都需要各自的虚拟地址空间，以及它们的区别。

#### 1. 用户进程虚拟地址和内核虚拟地址空间的主要区别

| **特性**                                | **用户虚拟地址空间**                   | **内核虚拟地址空间**               |
| --------------------------------------- | -------------------------------------- | ---------------------------------- |
| **访问权限**                            | 用户程序可访问，但无法访问内核地址空间 | 内核代码和服务独享，用户不可访问   |
| **地址空间隔离**                        | 每个用户进程有独立的虚拟地址空间       | 所有内核态代码共享同一虚拟地址空间 |
| **访问对象**                            | 进程代码、堆栈、数据段、动态内存       | 页表、设备驱动、内核代码、系统数据 |
| **内存映射**                            | 主要映射到用户的物理数据页             | 映射内核数据和所有硬件资源         |
| **安全性**                              | 通过地址隔离避免恶意访问               | 保持系统关键资源安全               |
| **TLB（Translation Lookaside Buffer）** | 进程切换时刷新                         | 始终保留内核部分，减少开销         |

#### **2. 为什么需要内核虚拟地址空间？**

1. **系统调用与内核态执行**：
   - 当用户进程需要执行系统调用（如文件读写、进程管理等），CPU会切换到**内核态**。此时需要进入内核虚拟地址空间，执行内核代码和服务。
2. **内核资源管理与安全隔离**：
   - 内核负责管理所有的系统资源，包括**进程调度、内存管理、文件系统、设备驱动**等。内核地址空间确保这些资源不被用户进程直接访问，从而防止非法访问和数据泄漏。
3. **硬件访问与设备驱动支持**：
   - 内核需要直接访问**硬件资源**（如磁盘、网络、内存控制器等）。这些硬件映射在内核地址空间中，而用户进程无法直接访问这些地址。
4. **提升性能与减少开销**：
   - 在内存映射过程中，部分内核代码和数据会映射到用户进程的虚拟地址空间中（如**共享库或缓冲区**）。但大部分关键内核数据只存在于内核虚拟地址空间，以确保性能和安全。

#### **3. 用户与内核虚拟地址空间的隔离**

- 用户态与内核态的切换：
  - 当程序在用户态执行时，只能访问用户虚拟地址空间。一旦触发系统调用或中断，CPU会切换到内核态，并允许访问内核地址空间。
- 防止进程间干扰：
  - 每个用户进程的虚拟地址空间都是独立的，互不干扰；而所有内核代码则共享一个地址空间，确保系统内核能够统一管理资源。

#### **4. 用户进程和内核虚拟地址的交互**

1. **系统调用**：
   - 用户进程通过**系统调用**进入内核态，访问内核虚拟地址空间中的服务。例如，读取文件时，内核代码会从内核地址空间的文件缓存中读取数据。
2. **共享内存映射**：
   - 在某些场景下（如高效数据传输），用户进程和内核可以通过**共享内存**映射实现数据交换。这些共享内存区域会同时出现在用户地址空间和内核地址空间中。

#### 5. 为什么不直接使用用户虚拟地址空间即可？

- **安全性问题**：
  如果内核代码和数据也映射在用户地址空间中，那么恶意程序可能会利用漏洞攻击系统资源。因此，内核必须独立管理自己的地址空间。
- **性能优化**：
  通过将关键数据映射在内核地址空间内，并让进程共享部分内核内存，可以减少切换时的开销。

#### **6. 总结**

用户进程的虚拟地址空间和内核虚拟地址空间分别承担了**应用程序执行**和**系统资源管理**的职责。两者的**隔离设计**确保了系统的安全性和稳定性，防止用户进程直接访问关键的系统资源，同时提供高效的进程间通信和系统调用支持。

- **用户虚拟地址空间**：每个进程独享，主要用于进程的代码、堆、栈和动态数据。
- **内核虚拟地址空间**：所有内核态代码共享，主要用于设备管理、页表、缓存和系统调用处理。

这种**分离与共享相结合**的设计，使得系统既安全又高效地运行，避免了资源冲突和不必要的性能损耗。

------

### ==补充：**内核中所说的内存是指什么？它操作的数据结构是什么？==

#### **1. 我们所说的“内存”是物理内存吗？**

- **内存的两层概念**：
  在操作系统中，“内存”可以指代**物理内存**（RAM）和**虚拟内存**。
  - **物理内存**是真实存在的硬件内存（RAM），用于存储进程的运行数据和内核数据。
  - **虚拟内存**是操作系统提供的抽象，给每个进程一个独立的地址空间，使其认为自己拥有完整的内存。
- **虚拟地址到物理地址映射**：
  内核通过**页表**（Page Table）将进程的虚拟地址映射到实际的物理内存地址。这使得不同进程的虚拟地址空间可以互相隔离，避免冲突。

#### **2. 内核中的内存指向什么？它操作的是什么数据结构？**

在操作系统内核中，内存主要用于以下几类关键数据结构和用途：

##### **（1）页表（Page Table）**

- **描述**：页表是虚拟地址与物理地址之间的映射表。
- **用途**：内核为每个进程维护一个独立的页表，并通过 MMU（Memory Management Unit）根据页表完成地址转换。
- **结构**：多级页表结构常用于减少页表的内存占用（如二级或三级页表）。

##### **（2）内存管理数据结构：Free Lists、Buddy System**

- **Free Lists**：内核使用空闲链表来跟踪未使用的物理页面，以便在需要时快速分配。
- **Buddy System**：内核通过 Buddy System 管理内存碎片，将连续的空闲内存块进行合并，方便大块内存的分配。

##### **（3）内核栈（Kernel Stack）**

- **描述**：每个进程在进入内核态时使用一个独立的内核栈，用于保存进程的内核态上下文。
- **用途**：用于处理系统调用、中断以及异常。

##### **（4）Slab 分配器（Slab Allocator）**

- **描述**：内核中用于管理小块内存分配的高效分配器。
- **用途**：分配内核对象，如文件描述符、进程控制块（PCB）、页表条目（PTE）等。

##### **（5）进程控制块（Process Control Block, PCB）**

- **描述**：每个进程对应一个 PCB 结构，包含进程的状态信息、寄存器内容、页表指针等。
- **用途**：内核使用 PCB 来管理进程的调度和切换。

##### **（6）内核缓存和文件系统缓冲区**

- **描述**：内核会使用部分内存作为缓存，提高磁盘和 I/O 操作的性能。
- **用途**：文件系统会将经常访问的数据缓存在内存中，以减少磁盘访问的频率。

#### 3. 内核如何管理内存？

1. **物理内存管理**：
   - 内核通过数据结构（如**Buddy System** 和 **Free Lists**）来管理物理内存块。
   - 当需要分配内存时，内核会从这些空闲内存块中找到合适的块进行分配。
2. **虚拟内存管理**：
   - 通过**页表**实现虚拟地址到物理地址的映射。
   - 当内存不足时，内核会使用**交换机制**（swap），将不常用的页面暂时写入磁盘，腾出物理内存。

#### 4. 总结

- **内核中的内存**可以指**物理内存和虚拟内存**。它通过虚拟内存管理的方式，给进程提供独立的地址空间，同时高效管理物理内存。
- **数据结构**：内核通过页表、PCB、Free Lists、Buddy System 等数据结构管理和分配内存。这些结构不仅提高了内存使用效率，还支持系统的稳定性和性能。

------

### ==补充：**内核代码中的“内存”概念：地址与数据结构的关系**==

严格来说，**操作系统内核**中并非直接使用“内存”这个数据结构来操作物理内存，而是**通过描述地址、页表、和内存块的元信息**来管理内存。这种设计使内核可以高效、灵活地操作虚拟和物理地址空间。下面具体分析内核中的“内存”概念与它涉及的核心数据结构。

#### **1. 内核中的“地址”与“内存”的关系**

1. **内核主要操作地址，不直接操作内存块**：
   - 内存中的数据通过地址来标识。**内核通过操作地址及其映射关系**（如页表）来访问、分配和管理内存，而不是直接以“内存”这个数据结构来操作。
2. **虚拟地址和物理地址的抽象层**：
   - 内核主要通过虚拟地址操作内存。这些虚拟地址在后台由 **页表** 映射到物理地址。地址是连接虚拟内存和物理内存的核心。

#### **2. 内核管理内存的关键数据结构**

尽管内核主要使用地址操作内存，但它通过一系列数据结构管理内存的分配、回收和映射。这些数据结构描述了物理内存和虚拟地址之间的关系，以及内存块的状态。

#### **（1）页表（Page Table）**

- **描述**：映射虚拟地址和物理地址的表。
- **用途**：支持虚拟内存管理，并确保进程之间的地址空间隔离。

#### **（2）Free Lists（空闲链表）**

- **描述**：用于管理未分配的物理页面，链表中的每个节点表示一个空闲的页面。
- **用途**：当有进程需要内存时，从链表中分配一个页面。

#### **（3）Buddy System（伙伴系统）**

- **描述**：用于管理连续内存块，解决内存碎片问题。
- **用途**：当需要分配较大块的连续物理内存时，使用 Buddy System 合并空闲块。

#### **（4）Slab 分配器（Slab Allocator）**

- **描述**：用于分配内核对象的小块内存。
- **用途**：高效管理频繁创建和销毁的小内存对象，如文件描述符和页表条目。

#### **（5）进程控制块（PCB, Process Control Block）**

- **描述**：每个进程的控制信息，包括页表指针、寄存器状态等。
- **用途**：内核通过 PCB 跟踪进程状态，并在调度时切换进程的地址空间。

#### **3. 内核中的地址描述与管理**

1. **地址空间描述符（VMA, Virtual Memory Area）**：
   - 内核使用 **VMA 结构**描述每个进程的虚拟地址空间。它记录了每个进程所使用的地址段，以及对应的权限和状态（如只读或可执行）。
2. **MMU 的参与**：
   - MMU 通过页表将虚拟地址映射为物理地址。在进程切换时，内核会加载新的页表地址到 **SATP 或 CR3** 寄存器，使 MMU 能够正确处理新的地址空间。

#### **4. 为什么内核使用地址而非直接操作内存？**

1. **抽象性和灵活性**：
   - 地址抽象层使得操作系统能够管理比物理内存更多的虚拟地址空间，并支持内存的按需分配和分页。
2. **安全性和隔离性**：
   - 通过地址空间隔离，不同进程之间无法直接访问彼此的内存，提升了系统的安全性。
3. **性能优化**：
   - 地址映射可以通过 **TLB（Translation Lookaside Buffer）** 等硬件加速。内存块本身不直接暴露在内核操作中，而是通过地址管理机制进行访问。

#### **5. 总结**

操作系统内核主要通过**地址和映射关系**来操作内存，而不是使用“内存”这一抽象数据结构。关键数据结构（如 **页表、Free List、Buddy System、VMA** 等）用于描述和管理地址的映射和内存的状态。这种设计确保了内核的内存管理**高效、安全且灵活**，并使得内核能够在复杂的虚拟内存系统中高效工作。

------



### ==**页表是在内核的 Free Memory 还是物理内存中？**==

这是一个非常常见且合理的问题。我们需要明确的是：**Free Memory 是物理内存的一部分**，而内核通过 Free Memory 管理系统中的可用物理内存。在这种背景下，页表的分配和管理过程就可以清楚理解了。

#### **1. Free Memory 是什么？**

- **Free Memory** 是**物理内存中的空闲部分**，由操作系统的内核负责管理。当系统需要创建新的页表、进程，或分配内存块时，内核会从 Free Memory 中分配相应的内存。
- 因此，页表虽然是在“Free Memory”中创建的，但本质上**这部分 Free Memory 仍然是物理内存**的一部分。它只是被标记为未使用，并在需要时按需分配。

#### **2. 页表的创建与管理**

- 当内核创建一个新的进程时，它会为该进程分配一个**独立的页表**。这些页表**物理上**存储在系统的**RAM（物理内存）**中，但逻辑上由内核中的 Free Memory 分配。
- 内核将页表的地址写入到寄存器中（如 **SATP** 在 RISC-V 或 **CR3** 在 x86 架构）。这些寄存器指向进程的**页表根目录的物理地址**，从而让 MMU 能够使用这些页表完成虚拟地址到物理地址的转换。

#### **3. 为什么要区分“内核管理”与“物理存储”？**

- 页表存储在物理内存中，但页表的**创建、初始化、更新和释放**都由**操作系统内核**负责。内核根据系统需求，使用 Free Memory 中的物理内存来管理这些页表。
- ==**Free Memory 只是管理层次的一个逻辑视角**，表示这是系统中可以随时分配的内存。因此，说“页表由内核在 Free Memory 中创建”并不矛盾，因为内核只是使用这部分物理内存来创建和管理页表。==

#### **4. 内核与用户进程如何共享页表管理？**

- **内核页表和用户页表是相互隔离的**，但它们都依赖于同一套物理内存系统。每个用户进程有独立的页表，当进程切换时，**CPU 会将对应进程的页表地址写入 SATP（或 CR3）寄存器**。
- 用户进程的虚拟地址映射不会直接使用内核的页表，但在某些系统中，内核可能会**映射部分内核地址空间到用户页表中**（例如共享内存或内核模块映射）。

#### 5. 总结

- **Free Memory** 是**物理内存的一部分**，用于操作系统动态管理内存资源。当内核需要为用户进程创建页表时，它会从 Free Memory 中分配物理内存。
- 页表的存储位置是物理内存，而它们的**分配、管理和维护**由**内核**负责。因此，描述页表“由内核在 Free Memory 中创建和管理”与“页表存储在物理内存中”并不冲突。这只是两种对同一过程的不同表述——**Free Memory 是物理内存的管理视角**。

这种设计确保了系统的**高效性和灵活性**，避免了内存资源的浪费，并实现了进程间的地址空间隔离。



------



# 4.5 内核页表（Kernel Page Table）详细总结

## 一、内核地址空间与物理地址的关系

### 1. 硬件决定的物理地址映射

- 主板设计人员决定了物理地址空间的映射：
  - 地址 **高于 0x80000000**：映射到 **DRAM**（易失性存储器）。
  - 地址 **低于 0x80000000**：映射到 **I/O设备**（如以太网、CLINT、PLIC）。

- **Boot ROM**：物理地址 0x1000 处保存启动代码，启动后跳转至 **0x80000000**，执行操作系统代码。

## 二、I/O设备的内存映射

### 1. I/O设备与内存映射的结构

- 物理地址低于 0x80000000 的部分主要映射到I/O设备：
  - **PLIC**（Platform-Level Interrupt Controller）：中断控制器。
  - **CLINT**（Core Local Interruptor）：本地中断控制器。
  - **UART0**：控制台与显示器交互的串口通信设备。
  - **VIRTIO Disk**：虚拟磁盘设备。

> **内存映射I/O**：通过对特定的物理地址执行读写操作，控制相应设备的行为，而非直接操作内存。

## 三、虚拟地址与物理地址的映射

### 1. XV6的虚拟地址空间

- ==XV6内核的虚拟地址大部分与物理地址一对一映射：==
  - 例如，虚拟地址 **0x02000000** 与物理地址 **0x02000000** 对应。
  - 这种简单的映射使内核代码更加易于理解。

## 四、内核堆栈与Guard Page的实现

### 1. Guard Page的作用

- Guard Page：一个不映射到物理地址的虚拟页，其PTE的Valid位未设置。
  - 如果内核堆栈溢出到Guard Page，触发**page fault**，避免数据损坏。

### 2. 双重映射技术

- 内核堆栈被映射了两次：

  1. 一次在 **高地址的虚拟内存空间**。
  2. 一次在 **低地址的内存区域**（PHYSTOP下）。

  - 使用高地址的映射版本可以更好地保护内核堆栈。

## 五、内核数据与代码的权限管理

### 1. Kernel Text与Kernel Data的访问权限

- **Kernel Text**（R-X）：只能读取和执行，防止代码段被篡改。
- **Kernel Data**（RW-）：可读写，但不可执行，防止数据伪装成代码执行。

- **权限管理**帮助尽早发现Bug，提升系统安全性。

## 六、用户进程与内核的内存管理

### 1. 用户进程的Kernel Stack

- 每个用户进程都有**专属的内核堆栈**，用于系统调用期间保存上下文。

### 2. 用户进程的Free Memory

- XV6使用

  Free Memory

  存放用户进程的页表、代码段和数据段。

  - 当Free Memory耗尽时，`fork`或`exec`操作会返回错误。

### 3. 用户进程的虚拟地址空间

- 用户进程的虚拟地址空间与内核的虚拟地址空间一样大，但实际使用率更低。

## 七、XV6的多进程内存管理

### 1. 内核如何为用户进程分配内存

- 用户进程的页表

  从Free Memory中分配，并加载到SATP寄存器中。

  - 从加载页表到SATP的那一刻起，处理器开始使用新的虚拟地址空间。

### 2. 多个进程的内存优化

- 虽然多个进程可以映射到同一个物理地址，但**XV6不会主动优化或合并映射**。

## 八、总结与思考

### 1. 内核页表的设计与应用

- XV6使用简单直接的虚拟地址与物理地址**一对一映射**，让代码易于理解和调试。
- **双重映射与Guard Page**展示了页表管理的灵活性。

### 2. 用户进程与内核的协调

- 用户进程的页表由内核分配，并通过SATP寄存器加载到CPU核中。
- **Free Memory的管理**决定了系统能同时运行的进程数量。

### 3. 实验中的关键点

- 学生在**page table实验**中需要实现进程间共享页的优化，并理解页表的管理逻辑。
- 学生还需掌握如何通过PTE设置内存权限，避免数据和代码段的错误交互。

------

通过本节课的学习，我们深入了解了**XV6内核页表的实现**及其背后的设计理念。掌握这些知识将帮助我们更好地理解操作系统内存管理的**核心机制**，并为后续的实验打下坚实的基础。
